{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import variation\n",
    "import glob\n",
    "import os\n",
    "import typingmod as typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## mounting to ION server\n",
    "# os.system(\"osascript -e 'mount volume \\\"smb://ion-nas.uoregon.edu\\\" \\\n",
    "#           as user name \\\"greenhouse\\\" with password \\\"password\\\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining function to organize bigrams into rows\n",
    "def bigram_byrow():\n",
    "    bigrams = []\n",
    "    for index, row in keys_intocolumns.iterrows():\n",
    "        for column in range(0, (len(keys_intocolumns.columns) - 1)):\n",
    "            if (keys_intocolumns[column][index] != None and float('nan')) and (keys_intocolumns[column + 1][index] != None and float('nan')):\n",
    "                bigram = (keys_intocolumns[column][index] + keys_intocolumns[column + 1][index])\n",
    "                bigram = (bigram.replace(\"'\", \"\")).replace(\" \", \"\")\n",
    "                iki = (main_df['key_resp.rt.%(second)d' % {'second':  column + 2 }][index] - main_df['key_resp.rt.%(first)d' % { 'first': column +1 }][index])\n",
    "                bigrams.append([index, column, bigram, iki, main_df['string'][index], main_df['resp_string'][index]])\n",
    "    return(bigrams)\n",
    "\n",
    "## defining function that separates words in to bigrams\n",
    "def bi_byword(word):\n",
    "    bi_results = []\n",
    "    for y in range(0, (len(word)-1)):\n",
    "        bigram = word[y] + word[y+1]\n",
    "        bi_results.append(bigram)\n",
    "    return bi_results\n",
    "\n",
    "## defining function that separates all words into bigrams\n",
    "def bi_allwords():\n",
    "    bigrams = []\n",
    "    for word in df['string']:\n",
    "        bigrams.append(bi_byword(word))\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/greenhouse/typingtask_data/subject_data/s262_01232024/psychopy_data/edited/s262_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s262_01232024/psychopy_data/edited/s262_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s261_12122023/psychopy_data/edited/s261_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s261_12122023/psychopy_data/edited/s261_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s240_11162023/psychopy_data/edited/s240_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s240_11162023/psychopy_data/edited/s240_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s217_11092023/psychopy_data/edited/s217_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s217_11092023/psychopy_data/edited/s217_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s176_10262023/psychopy_data/edited/s176_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s176_10262023/psychopy_data/edited/s176_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s267_02122024/psychopy_data/edited/s267_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s267_02122024/psychopy_data/edited/s267_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s263_01312024/psychopy_data/edited/s263_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s263_01312024/psychopy_data/edited/s263_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s254_11022023/psychopy_data/edited/s254_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s254_11022023/psychopy_data/edited/s254_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s209_09202023/psychopy_data/edited/s209_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s209_09202023/psychopy_data/edited/s209_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s276_02212024/psychopy_data/edited/s276_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s276_02212024/psychopy_data/edited/s276_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s278_02232024/psychopy_data/edited/s278_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s278_02232024/psychopy_data/edited/s278_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s279_02232024/psychopy_data/edited/s279_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s279_02232024/psychopy_data/edited/s279_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s282_02292024/psychopy_data/edited/s282_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s282_02292024/psychopy_data/edited/s282_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s283_02292024/psychopy_data/edited/s283_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s283_02292024/psychopy_data/edited/s283_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s286_03082024/psychopy_data/edited/s286_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s286_03082024/psychopy_data/edited/s286_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s302_05282024/psychopy_data/edited/s302_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s302_05282024/psychopy_data/edited/s302_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s304_07102024/psychopy_data/edited/s304_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s304_07102024/psychopy_data/edited/s304_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s306_07122024/psychopy_data/edited/s306_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s306_07122024/psychopy_data/edited/s306_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s305_07112024/psychopy_data/edited/s305_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s305_07112024/psychopy_data/edited/s305_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s309_09232024/psychopy_data/edited/s309_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s309_09232024/psychopy_data/edited/s309_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s311_10152024/psychopy_data/edited/s311_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s311_10152024/psychopy_data/edited/s311_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s009_02162024/psychopy_data/edited/s009_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s009_02162024/psychopy_data/edited/s009_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s020_02082024/psychopy_data/edited/s020_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s020_02082024/psychopy_data/edited/s020_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s207_09212023/psychopy_data/edited/s207_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s207_09212023/psychopy_data/edited/s207_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s313_11192024/psychopy_data/edited/s313_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s313_11192024/psychopy_data/edited/s313_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s336_01232025/psychopy_data/edited/s336_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s336_01232025/psychopy_data/edited/s336_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s344_02212025/psychopy_data/edited/s344_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s344_02212025/psychopy_data/edited/s344_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s345_02212025/psychopy_data/edited/s345_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s345_02212025/psychopy_data/edited/s345_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s347_03072025/psychopy_data/edited/s347_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s347_03072025/psychopy_data/edited/s347_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s348_05062025/psychopy_data/edited/s348_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s348_05062025/psychopy_data/edited/s348_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s349_05092025/psychopy_data/edited/s349_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s349_05092025/psychopy_data/edited/s349_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s350_05142025/psychopy_data/edited/s350_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s350_05142025/psychopy_data/edited/s350_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s351_05162025/psychopy_data/edited/s351_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s351_05162025/psychopy_data/edited/s351_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s352_05272025/psychopy_data/edited/s352_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/s352_05272025/psychopy_data/edited/s352_bybigram.csv\n"
     ]
    }
   ],
   "source": [
    "## create dataframes tiral-based and bigram-based dataframes for each subject ##\n",
    "\n",
    "## importing experiment data\n",
    "server = r'/Volumes/greenhouse/typingtask_data/subject_data'\n",
    "server_noturbo = r'/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/'\n",
    "\n",
    "# looping through subjects\n",
    "os.chdir(server)\n",
    "folders = os.listdir()\n",
    "sub_folders = list(filter(lambda x: x.startswith('s', 0, 1), folders))\n",
    "for sub in sub_folders:\n",
    "    sub_folder = r'/Volumes/greenhouse/typingtask_data/subject_data/%s/psychopy_data/' % sub\n",
    "    os.chdir(sub_folder)\n",
    "    sID = sub.split('_', 1)[0]\n",
    "    og_df = pd.read_csv(glob.glob('*.csv')[0])   \n",
    "\n",
    "## filters through subjects without turbotyping data\n",
    "# os.chdir(server_noturbo)\n",
    "# folders = os.listdir()\n",
    "# sub_folders = list(filter(lambda x: x.startswith('s', 0, 1), folders))\n",
    "# for sub in sub_folders:\n",
    "#     sub_folder = server_noturbo + r'%s/psychopy_data/' % sub\n",
    "#     os.chdir(sub_folder)\n",
    "#     sID = sub.split('_', 1)[0]\n",
    "#     og_df = pd.read_csv(glob.glob('*.csv')[0])  \n",
    "   \n",
    "    ## deleting first 3 practice trials -- EDIT FOR ANY TRIALS YOU WANT TO IMMEDIATELY EXCLUDE\n",
    "    df = (og_df.drop(labels=[0, 1, 2], axis=0)).reset_index(drop = True) \n",
    "    \n",
    "    ## expanding nested key_resp.rt values into separate columns, making new dataframe, and turning values back into floats from strings\n",
    "    stripped_rts_1 = ((df['key_resp_1.rt'].str.strip('[,]')).dropna()).str.split(',', expand = True)\n",
    "    stripped_rts_2 = ((df['key_resp_2.rt'].str.strip('[,]')).dropna()).str.split(',', expand = True)\n",
    "    rts_intocolumns = (pd.concat([stripped_rts_1, stripped_rts_2])).reset_index(drop = True)\n",
    "    \n",
    "    ## renames rt columns to automatically match dataset\n",
    "    DF = rts_intocolumns\n",
    "    renamed_rt = DF.rename(columns = { 0:'key_resp.rt.%s' %(0+1) })\n",
    "    for n in range(0, len(DF.columns)):\n",
    "        renamed_rt = renamed_rt.rename(columns = { n:'key_resp.rt.%s' %(n+1) })\n",
    "    expanded_rts = renamed_rt.astype(float).fillna(0) ##replacing NaNs with zeroes\n",
    "\n",
    "    ## expanding nested key_resp.keys values into separate columns and making new dataframe\n",
    "    stripped_keys_1 = ((df['key_resp_1.keys'].str.strip('[,]')).dropna()).str.split(',', expand = True)\n",
    "    stripped_keys_2 = ((df['key_resp_2.keys'].str.strip('[,]')).dropna()).str.split(',', expand = True)\n",
    "    keys_intocolumns = (pd.concat([stripped_keys_1, stripped_keys_2])).reset_index(drop = True)\n",
    "    keys_intocolumns = keys_intocolumns.where(pd.notnull(keys_intocolumns), None) \n",
    "        # ^ also replaces any added NaNs with Nones\n",
    "\n",
    "    ## renames key columns to automatically match dataset\n",
    "    DF = keys_intocolumns\n",
    "    expanded_keys = DF.rename(columns = { 0:'key_resp.keys.%s' %(0+1) })\n",
    "    for n in range(0, len(DF.columns)):\n",
    "        expanded_keys = expanded_keys.rename(columns = { n:'key_resp.keys.%s' %(n+1) })\n",
    "\n",
    "    ## getting rid of apostrophes and spaces in key values\n",
    "    cols_to_change = (expanded_keys.iloc[:, 0:])\n",
    "    for col in cols_to_change:\n",
    "        expanded_keys[col] = expanded_keys[col].str.replace(\"'\", \"\")\n",
    "        expanded_keys[col] = expanded_keys[col].str.replace(\" \", \"\")\n",
    "\n",
    "    ## combining key_resp.keys into one simple string to easily represent typed responses\n",
    "    responses_1 = pd.DataFrame((df['key_resp_1.keys'].str.replace(\"[', ]\", \"\", regex=True).str.strip(\"[]\")).dropna()).rename(columns = {'key_resp_1.keys':'resp_string'})\n",
    "    responses_2 = pd.DataFrame((df['key_resp_2.keys'].str.replace(\"[', ]\", \"\", regex=True).str.strip(\"[]\")).dropna()).rename(columns = {'key_resp_2.keys':'resp_string'})\n",
    "    responses = (pd.concat([responses_1, responses_2])).reset_index(drop = True)\n",
    "\n",
    "    ## identifying bigrams in words to add to larger dataframe\n",
    "    task_bigrams = pd.DataFrame(bi_allwords())\n",
    "    task_bigrams.columns = ['bi_1', 'bi_2', 'bi_3', 'bi_4']\n",
    "    \n",
    "    ## combining expanded rt, expanded keys, and response string values with column for strings typed each trial to create more useful dataframe\n",
    "    ## (does not have all the random timing data of other events occuring during the task)\n",
    "    main_df = pd.concat([responses, task_bigrams, expanded_keys, expanded_rts], axis = 1)\n",
    "    main_df.insert(0, 'string', df['string'], True)\n",
    "\n",
    "    ## creating column for WF type for each trial\n",
    "    main_df['wf_type'] = \"\"\n",
    "    for index, data in main_df.iterrows():\n",
    "        if main_df.loc[index, 'string'] in typ.highwf:\n",
    "            main_df.loc[index, 'wf_type'] = 'highwf'\n",
    "        if main_df.loc[index, 'string'] in typ.medwf:\n",
    "            main_df.loc[index, 'wf_type'] = 'medwf'\n",
    "        if main_df.loc[index, 'string'] in typ.lowwf:\n",
    "            main_df.loc[index, 'wf_type'] = 'lowwf'\n",
    "        if main_df.loc[index, 'string'] in typ.pseudo:\n",
    "            main_df.loc[index, 'wf_type'] = 'pseudo'\n",
    "\n",
    "    ## creating column for BF type for each trial\n",
    "    main_df['meanbf_type'] = \"\"\n",
    "    for index, data in main_df.iterrows():\n",
    "        if main_df.loc[index, 'string'] in typ.avg_highbf:\n",
    "            main_df.loc[index, 'meanbf_type'] = 'highbf'\n",
    "        if main_df.loc[index, 'string'] in typ.avg_medbf:\n",
    "            main_df.loc[index, 'meanbf_type'] = 'medbf'\n",
    "        if main_df.loc[index, 'string'] in typ.avg_lowbf:\n",
    "            main_df.loc[index, 'meanbf_type'] = 'lowbf'\n",
    "\n",
    "    ## creating column for trial (useful for group analysis)\n",
    "    trial_nums = []\n",
    "    for index, data in main_df.iterrows():\n",
    "        trial_nums.append(index)\n",
    "    main_df.insert(0, 'trial_num', trial_nums)\n",
    "\n",
    "    ## creating column for subject ID (also useful for group analysis)\n",
    "    main_ID = [sID]*len(main_df)\n",
    "    main_df.insert(0, 'sID', main_ID)\n",
    "\n",
    "    ## creating columns for word repetition number\n",
    "    main_df.insert(2, 'rep_num', '')\n",
    "    main_df['rep_num'] = main_df.groupby(['sID', 'string']).cumcount()\n",
    "\n",
    "    ## creating column for if trial is correct or not\n",
    "    main_df['trial_corr'] = ''\n",
    "    corr_trials = (main_df[main_df.string \n",
    "                   == main_df.resp_string])\n",
    "    corr_indices = list(corr_trials.index.values)\n",
    "    main_df.loc[corr_indices, 'trial_corr'] = True\n",
    "    \n",
    "    incorr_trials = (main_df[main_df.string \n",
    "                     != main_df.resp_string])\n",
    "    incorr_indices = list(incorr_trials.index.values)\n",
    "    main_df.loc[incorr_indices, 'trial_corr'] = False\n",
    "    \n",
    "    ## making csv from dataframe\n",
    "    edited_path = os.path.join(sub_folder, 'edited')\n",
    "    if os.path.exists(edited_path) == False:\n",
    "        os.mkdir(edited_path)\n",
    "    bytrial_path = os.path.join(edited_path, '%s_bytrial.csv' % sID)\n",
    "    print(bytrial_path)\n",
    "    main_df.to_csv(bytrial_path)\n",
    "\n",
    "    \n",
    "    ## BIGRAM DATAFRAME ##\n",
    "    bigram_df = (pd.DataFrame(bigram_byrow())).rename(columns={0: \"trial_num\", 1: \"bigram_loc\",  2:\"resp_bigram\", 3: \"IKI\", 4: \"string\", 5: \"resp_string\"})\n",
    "\n",
    "    ## creating column for bigram # (useful for group analysis)\n",
    "    bigram_nums = []\n",
    "    for index, data in bigram_df.iterrows():\n",
    "        bigram_nums.append(index)\n",
    "    bigram_df.insert(0, 'bigram_num', bigram_nums)\n",
    "\n",
    "    ## creating column for subject ID (also useful for group analysis)\n",
    "    bigram_ID = [sID]*len(bigram_df)\n",
    "    bigram_df.insert(0, 'sID', bigram_ID)\n",
    "\n",
    "    ## creating column for correct bigram (as opposed to the typed bigram)\n",
    "    bigram_df.insert(4, 'bigram', '')\n",
    "    for index, row in bigram_df.iterrows():\n",
    "        loc = bigram_df.loc[index, 'bigram_loc']\n",
    "        loc_list = [0, 1, 2, 3]\n",
    "        if loc in loc_list:\n",
    "            corr = bi_byword(bigram_df.loc[index, 'string'])[loc]\n",
    "        else:\n",
    "            corr = ''\n",
    "        bigram_df.loc[index, 'bigram'] = corr\n",
    "\n",
    "    ## creating column for rep #\n",
    "    bigram_df.insert(3, 'rep_num', '')\n",
    "    bigram_df['rep_num'] = bigram_df.groupby(['sID', 'string', 'bigram']).cumcount()\n",
    "    \n",
    "    ## creating column for bigram frequency\n",
    "    bg_freqs = pd.read_csv(r'/Users/rubi/Desktop/Github/typingexp/typing_task_analysis/bg_freqs.csv') ## EDIT TO MAKE USEFUL ON OTHER COMPUTERS\n",
    "    bg_freqs.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "    freq_dict = bg_freqs.set_index('Bigrams')['Frequency'].to_dict()\n",
    "    bigram_df['bg_freq'] = bigram_df['bigram'].map(freq_dict)\n",
    "\n",
    "    ## creating column for bigram type\n",
    "    name_list = ['high', 'med', 'low', 'pseudo']\n",
    "\n",
    "    for index, bf_type in enumerate(typ.bf_types):\n",
    "        by_bf = bigram_df[bigram_df.bigram.isin(bf_type)]\n",
    "        rows = by_bf.index\n",
    "        bigram_df.loc[rows, 'bf_type'] = name_list[index]\n",
    "\n",
    "    ## creating a column for mean bigram type\n",
    "    for index, avgbf_type in enumerate(typ.avgbf_types):\n",
    "        by_bf = bigram_df[bigram_df.string.isin(avgbf_type)]\n",
    "        rows = by_bf.index\n",
    "        bigram_df.loc[rows, 'meanbf_type'] = name_list[index]\n",
    "\n",
    "    ## creating a column for mean bigram type\n",
    "    for index, wf_type in enumerate(typ.wf_types):\n",
    "        by_wf = bigram_df[bigram_df.string.isin(wf_type)]\n",
    "        rows = by_wf.index\n",
    "        bigram_df.loc[rows, 'wf_type'] = name_list[index]\n",
    "\n",
    "    ## creating column for if trial is correct or not\n",
    "    bigram_df['trial_corr'] = ''\n",
    "    corr_trials_bybg = (bigram_df[bigram_df.string \n",
    "                   == bigram_df.resp_string])\n",
    "    corr_indices_bybg = list(corr_trials_bybg.index.values)\n",
    "    bigram_df.loc[corr_indices_bybg, 'trial_corr'] = True\n",
    "    \n",
    "    incorr_trials_bybg = (bigram_df[bigram_df.string \n",
    "                     != bigram_df.resp_string])\n",
    "    incorr_indices_bybg = list(incorr_trials_bybg.index.values)\n",
    "    bigram_df.loc[incorr_indices_bybg, 'trial_corr'] = False\n",
    "\n",
    "    ## creating column for if bigram is correct or not\n",
    "    bigram_df['bg_corr'] = ''\n",
    "    corr_bgs = (bigram_df[bigram_df.bigram \n",
    "                   == bigram_df.resp_bigram])\n",
    "    corr_bg_indices = list(corr_bgs.index.values)\n",
    "    bigram_df.loc[corr_bg_indices, 'bg_corr'] = True\n",
    "    \n",
    "    incorr_bgs = (bigram_df[bigram_df.bigram \n",
    "                     != bigram_df.resp_bigram])\n",
    "    incorr_bg_indices = list(incorr_bgs.index.values)\n",
    "    bigram_df.loc[incorr_bg_indices, 'bg_corr'] = False\n",
    "\n",
    "    ## making csv from dataframe\n",
    "    bybigram_path = os.path.join(edited_path, '%s_bybigram.csv' % sID)\n",
    "    print(bybigram_path)\n",
    "    bigram_df.to_csv(bybigram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sID</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>rep_num</th>\n",
       "      <th>string</th>\n",
       "      <th>resp_string</th>\n",
       "      <th>bi_1</th>\n",
       "      <th>bi_2</th>\n",
       "      <th>bi_3</th>\n",
       "      <th>bi_4</th>\n",
       "      <th>key_resp.keys.1</th>\n",
       "      <th>...</th>\n",
       "      <th>key_resp.rt.3</th>\n",
       "      <th>key_resp.rt.4</th>\n",
       "      <th>key_resp.rt.5</th>\n",
       "      <th>key_resp.rt.6</th>\n",
       "      <th>key_resp.rt.7</th>\n",
       "      <th>key_resp.rt.8</th>\n",
       "      <th>key_resp.rt.9</th>\n",
       "      <th>wf_type</th>\n",
       "      <th>meanbf_type</th>\n",
       "      <th>trial_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kremp</td>\n",
       "      <td>kremp</td>\n",
       "      <td>kr</td>\n",
       "      <td>re</td>\n",
       "      <td>em</td>\n",
       "      <td>mp</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>1.140524</td>\n",
       "      <td>1.220496</td>\n",
       "      <td>1.404501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>medbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s352</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>cooed</td>\n",
       "      <td>cooed</td>\n",
       "      <td>co</td>\n",
       "      <td>oo</td>\n",
       "      <td>oe</td>\n",
       "      <td>ed</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>1.392854</td>\n",
       "      <td>1.744871</td>\n",
       "      <td>1.968891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lowwf</td>\n",
       "      <td>medbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s352</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>lucky</td>\n",
       "      <td>lucky</td>\n",
       "      <td>lu</td>\n",
       "      <td>uc</td>\n",
       "      <td>ck</td>\n",
       "      <td>ky</td>\n",
       "      <td>l</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060956</td>\n",
       "      <td>1.172912</td>\n",
       "      <td>1.781021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>highwf</td>\n",
       "      <td>lowbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s352</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "      <td>th</td>\n",
       "      <td>hi</td>\n",
       "      <td>in</td>\n",
       "      <td>nk</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840853</td>\n",
       "      <td>1.032898</td>\n",
       "      <td>1.200913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>highwf</td>\n",
       "      <td>highbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>vanru</td>\n",
       "      <td>vanru</td>\n",
       "      <td>va</td>\n",
       "      <td>an</td>\n",
       "      <td>nr</td>\n",
       "      <td>ru</td>\n",
       "      <td>v</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004772</td>\n",
       "      <td>1.124729</td>\n",
       "      <td>1.292737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>medbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>s352</td>\n",
       "      <td>235</td>\n",
       "      <td>9</td>\n",
       "      <td>cooed</td>\n",
       "      <td>cooed</td>\n",
       "      <td>co</td>\n",
       "      <td>oo</td>\n",
       "      <td>oe</td>\n",
       "      <td>ed</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790753</td>\n",
       "      <td>0.894767</td>\n",
       "      <td>1.022779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lowwf</td>\n",
       "      <td>medbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>s352</td>\n",
       "      <td>236</td>\n",
       "      <td>9</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>wo</td>\n",
       "      <td>ou</td>\n",
       "      <td>ul</td>\n",
       "      <td>ld</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754776</td>\n",
       "      <td>0.946814</td>\n",
       "      <td>1.066801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>highwf</td>\n",
       "      <td>medbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>s352</td>\n",
       "      <td>237</td>\n",
       "      <td>9</td>\n",
       "      <td>buddy</td>\n",
       "      <td>buddy</td>\n",
       "      <td>bu</td>\n",
       "      <td>ud</td>\n",
       "      <td>dd</td>\n",
       "      <td>dy</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846683</td>\n",
       "      <td>0.998714</td>\n",
       "      <td>1.062698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>highwf</td>\n",
       "      <td>lowbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>s352</td>\n",
       "      <td>238</td>\n",
       "      <td>9</td>\n",
       "      <td>zibja</td>\n",
       "      <td>zibja</td>\n",
       "      <td>zi</td>\n",
       "      <td>ib</td>\n",
       "      <td>bj</td>\n",
       "      <td>ja</td>\n",
       "      <td>z</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738595</td>\n",
       "      <td>0.834654</td>\n",
       "      <td>0.946557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>lowbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>s352</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>ch</td>\n",
       "      <td>ha</td>\n",
       "      <td>am</td>\n",
       "      <td>mp</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694478</td>\n",
       "      <td>0.822457</td>\n",
       "      <td>1.038460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medwf</td>\n",
       "      <td>medbf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sID  trial_num  rep_num string resp_string bi_1 bi_2 bi_3 bi_4  \\\n",
       "0    s352          0        0  kremp       kremp   kr   re   em   mp   \n",
       "1    s352          1        0  cooed       cooed   co   oo   oe   ed   \n",
       "2    s352          2        0  lucky       lucky   lu   uc   ck   ky   \n",
       "3    s352          3        0  think       think   th   hi   in   nk   \n",
       "4    s352          4        0  vanru       vanru   va   an   nr   ru   \n",
       "..    ...        ...      ...    ...         ...  ...  ...  ...  ...   \n",
       "235  s352        235        9  cooed       cooed   co   oo   oe   ed   \n",
       "236  s352        236        9  would       would   wo   ou   ul   ld   \n",
       "237  s352        237        9  buddy       buddy   bu   ud   dd   dy   \n",
       "238  s352        238        9  zibja       zibja   zi   ib   bj   ja   \n",
       "239  s352        239        9  champ       champ   ch   ha   am   mp   \n",
       "\n",
       "    key_resp.keys.1  ... key_resp.rt.3 key_resp.rt.4 key_resp.rt.5  \\\n",
       "0                 k  ...      1.140524      1.220496      1.404501   \n",
       "1                 c  ...      1.392854      1.744871      1.968891   \n",
       "2                 l  ...      1.060956      1.172912      1.781021   \n",
       "3                 t  ...      0.840853      1.032898      1.200913   \n",
       "4                 v  ...      1.004772      1.124729      1.292737   \n",
       "..              ...  ...           ...           ...           ...   \n",
       "235               c  ...      0.790753      0.894767      1.022779   \n",
       "236               w  ...      0.754776      0.946814      1.066801   \n",
       "237               b  ...      0.846683      0.998714      1.062698   \n",
       "238               z  ...      0.738595      0.834654      0.946557   \n",
       "239               c  ...      0.694478      0.822457      1.038460   \n",
       "\n",
       "    key_resp.rt.6 key_resp.rt.7 key_resp.rt.8 key_resp.rt.9 wf_type  \\\n",
       "0             0.0           0.0           0.0           0.0  pseudo   \n",
       "1             0.0           0.0           0.0           0.0   lowwf   \n",
       "2             0.0           0.0           0.0           0.0  highwf   \n",
       "3             0.0           0.0           0.0           0.0  highwf   \n",
       "4             0.0           0.0           0.0           0.0  pseudo   \n",
       "..            ...           ...           ...           ...     ...   \n",
       "235           0.0           0.0           0.0           0.0   lowwf   \n",
       "236           0.0           0.0           0.0           0.0  highwf   \n",
       "237           0.0           0.0           0.0           0.0  highwf   \n",
       "238           0.0           0.0           0.0           0.0  pseudo   \n",
       "239           0.0           0.0           0.0           0.0   medwf   \n",
       "\n",
       "     meanbf_type  trial_corr  \n",
       "0          medbf        True  \n",
       "1          medbf        True  \n",
       "2          lowbf        True  \n",
       "3         highbf        True  \n",
       "4          medbf        True  \n",
       "..           ...         ...  \n",
       "235        medbf        True  \n",
       "236        medbf        True  \n",
       "237        lowbf        True  \n",
       "238        lowbf        True  \n",
       "239        medbf        True  \n",
       "\n",
       "[240 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can also be specified\n",
    "#     print(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sID</th>\n",
       "      <th>bigram_num</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>rep_num</th>\n",
       "      <th>bigram_loc</th>\n",
       "      <th>bigram</th>\n",
       "      <th>resp_bigram</th>\n",
       "      <th>IKI</th>\n",
       "      <th>string</th>\n",
       "      <th>resp_string</th>\n",
       "      <th>bg_freq</th>\n",
       "      <th>bf_type</th>\n",
       "      <th>meanbf_type</th>\n",
       "      <th>wf_type</th>\n",
       "      <th>trial_corr</th>\n",
       "      <th>bg_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kr</td>\n",
       "      <td>kr</td>\n",
       "      <td>0.120039</td>\n",
       "      <td>kremp</td>\n",
       "      <td>kremp</td>\n",
       "      <td>5683.0</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s352</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>re</td>\n",
       "      <td>re</td>\n",
       "      <td>0.087961</td>\n",
       "      <td>kremp</td>\n",
       "      <td>kremp</td>\n",
       "      <td>10687711.0</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s352</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>em</td>\n",
       "      <td>em</td>\n",
       "      <td>0.079972</td>\n",
       "      <td>kremp</td>\n",
       "      <td>kremp</td>\n",
       "      <td>2039661.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s352</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.184005</td>\n",
       "      <td>kremp</td>\n",
       "      <td>kremp</td>\n",
       "      <td>1042198.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s352</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>co</td>\n",
       "      <td>co</td>\n",
       "      <td>0.488022</td>\n",
       "      <td>cooed</td>\n",
       "      <td>cooed</td>\n",
       "      <td>3609272.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>s352</td>\n",
       "      <td>959</td>\n",
       "      <td>238</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>0.111903</td>\n",
       "      <td>zibja</td>\n",
       "      <td>zibja</td>\n",
       "      <td>40073.0</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>s352</td>\n",
       "      <td>960</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>ch</td>\n",
       "      <td>ch</td>\n",
       "      <td>0.128008</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>3267507.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>s352</td>\n",
       "      <td>961</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>ha</td>\n",
       "      <td>ha</td>\n",
       "      <td>0.127948</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>6967591.0</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>s352</td>\n",
       "      <td>962</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>am</td>\n",
       "      <td>am</td>\n",
       "      <td>0.127979</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>1610395.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>s352</td>\n",
       "      <td>963</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.216003</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>1042198.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sID  bigram_num  trial_num  rep_num  bigram_loc bigram resp_bigram  \\\n",
       "0    s352           0          0        0           0     kr          kr   \n",
       "1    s352           1          0        0           1     re          re   \n",
       "2    s352           2          0        0           2     em          em   \n",
       "3    s352           3          0        0           3     mp          mp   \n",
       "4    s352           4          1        0           0     co          co   \n",
       "..    ...         ...        ...      ...         ...    ...         ...   \n",
       "959  s352         959        238        9           3     ja          ja   \n",
       "960  s352         960        239        9           0     ch          ch   \n",
       "961  s352         961        239        9           1     ha          ha   \n",
       "962  s352         962        239        9           2     am          am   \n",
       "963  s352         963        239        9           3     mp          mp   \n",
       "\n",
       "          IKI string resp_string     bg_freq bf_type meanbf_type wf_type  \\\n",
       "0    0.120039  kremp       kremp      5683.0     low         med  pseudo   \n",
       "1    0.087961  kremp       kremp  10687711.0    high         med  pseudo   \n",
       "2    0.079972  kremp       kremp   2039661.0     med         med  pseudo   \n",
       "3    0.184005  kremp       kremp   1042198.0     med         med  pseudo   \n",
       "4    0.488022  cooed       cooed   3609272.0     med         med     low   \n",
       "..        ...    ...         ...         ...     ...         ...     ...   \n",
       "959  0.111903  zibja       zibja     40073.0     low         low  pseudo   \n",
       "960  0.128008  champ       champ   3267507.0     med         med     med   \n",
       "961  0.127948  champ       champ   6967591.0    high         med     med   \n",
       "962  0.127979  champ       champ   1610395.0     med         med     med   \n",
       "963  0.216003  champ       champ   1042198.0     med         med     med   \n",
       "\n",
       "    trial_corr bg_corr  \n",
       "0         True    True  \n",
       "1         True    True  \n",
       "2         True    True  \n",
       "3         True    True  \n",
       "4         True    True  \n",
       "..         ...     ...  \n",
       "959       True    True  \n",
       "960       True    True  \n",
       "961       True    True  \n",
       "962       True    True  \n",
       "963       True    True  \n",
       "\n",
       "[964 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can also be specified\n",
    "#     print(bigram_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
