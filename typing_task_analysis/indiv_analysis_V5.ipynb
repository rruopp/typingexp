{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import variation\n",
    "import glob\n",
    "import os\n",
    "import typingmod as typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## mounting to ION server\n",
    "# os.system(\"osascript -e 'mount volume \\\"smb://ion-nas.uoregon.edu\\\" \\\n",
    "#           as user name \\\"greenhouse\\\" with password \\\"password\\\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining function to organize bigrams into rows\n",
    "def bigram_byrow():\n",
    "    bigrams = []\n",
    "    for index, row in keys_intocolumns.iterrows():\n",
    "        for column in range(0, (len(keys_intocolumns.columns) - 1)):\n",
    "            if (keys_intocolumns[column][index] != None and float('nan')) and (keys_intocolumns[column + 1][index] != None and float('nan')):\n",
    "                bigram = (keys_intocolumns[column][index] + keys_intocolumns[column + 1][index])\n",
    "                bigram = (bigram.replace(\"'\", \"\")).replace(\" \", \"\")\n",
    "                iki = (main_df['key_resp.rt.%(second)d' % {'second':  column + 2 }][index] - main_df['key_resp.rt.%(first)d' % { 'first': column +1 }][index])\n",
    "                bigrams.append([index, column, bigram, iki, main_df['string'][index], main_df['resp_string'][index]])\n",
    "    return(bigrams)\n",
    "\n",
    "## defining function that separates words in to bigrams\n",
    "def bi_byword(word):\n",
    "    bi_results = []\n",
    "    for y in range(0, (len(word)-1)):\n",
    "        bigram = word[y] + word[y+1]\n",
    "        bi_results.append(bigram)\n",
    "    return bi_results\n",
    "\n",
    "## defining function that separates all words into bigrams\n",
    "def bi_allwords():\n",
    "    bigrams = []\n",
    "    for word in df['string']:\n",
    "        bigrams.append(bi_byword(word))\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s20_09012022/psychopy_data/edited/s20_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s20_09012022/psychopy_data/edited/s20_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s175_08032022/psychopy_data/edited/s175_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s175_08032022/psychopy_data/edited/s175_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s178_08302022/psychopy_data/edited/s178_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s178_08302022/psychopy_data/edited/s178_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s180_10102022/psychopy_data/edited/s180_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s180_10102022/psychopy_data/edited/s180_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s181_10132022/psychopy_data/edited/s181_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s181_10132022/psychopy_data/edited/s181_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s182_10192022/psychopy_data/edited/s182_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s182_10192022/psychopy_data/edited/s182_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s183_10272022/psychopy_data/edited/s183_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s183_10272022/psychopy_data/edited/s183_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s189_11222022/psychopy_data/edited/s189_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s189_11222022/psychopy_data/edited/s189_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s190_11222022/psychopy_data/edited/s190_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s190_11222022/psychopy_data/edited/s190_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s198_02202023/psychopy_data/edited/s198_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s198_02202023/psychopy_data/edited/s198_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s207_09212023/psychopy_data/edited/s207_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s207_09212023/psychopy_data/edited/s207_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s209_09202023/psychopy_data/edited/s209_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s209_09202023/psychopy_data/edited/s209_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s210_03102023/psychopy_data/edited/s210_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s210_03102023/psychopy_data/edited/s210_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s212_10032023/psychopy_data/edited/s212_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s212_10032023/psychopy_data/edited/s212_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s219_04132023/psychopy_data/edited/s219_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s219_04132023/psychopy_data/edited/s219_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s224_04212023/psychopy_data/edited/s224_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s224_04212023/psychopy_data/edited/s224_bybigram.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s217_04122023/psychopy_data/edited/s217_bytrial.csv\n",
      "/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/s217_04122023/psychopy_data/edited/s217_bybigram.csv\n"
     ]
    }
   ],
   "source": [
    "## create dataframes tiral-based and bigram-based dataframes for each subject ##\n",
    "\n",
    "## importing experiment data\n",
    "server = r'/Volumes/greenhouse/typingtask_data/subject_data'\n",
    "server_noturbo = r'/Volumes/greenhouse/typingtask_data/subject_data/not_used/no_turbotyping/'\n",
    "os.chdir(server)\n",
    "folders = os.listdir()\n",
    "\n",
    "# looping through subjects\n",
    "sub_folders = list(filter(lambda x: x.startswith('s', 0, 1), folders))\n",
    "for sub in sub_folders:\n",
    "    sub_folder = r'/Volumes/greenhouse/typingtask_data/subject_data/%s/psychopy_data/' % sub\n",
    "    os.chdir(sub_folder)\n",
    "    sID = sub.split('_', 1)[0]\n",
    "    og_df = pd.read_csv(glob.glob('*.csv')[0])   \n",
    "\n",
    "## filters through subjects without turbotyping data\n",
    "# sub_folders = list(filter(lambda x: x.startswith('s', 0, 1), folders))\n",
    "# for sub in sub_folders:\n",
    "#     sub_folder = server_noturbo + r'%s/psychopy_data/' % sub\n",
    "#     os.chdir(sub_folder)\n",
    "#     sID = sub.split('_', 1)[0]\n",
    "#     og_df = pd.read_csv(glob.glob('*.csv')[0])  \n",
    "   \n",
    "    ## deleting first 3 practice trials -- EDIT FOR ANY TRIALS YOU WANT TO IMMEDIATELY EXCLUDE\n",
    "    df = (og_df.drop(labels=[0, 1, 2], axis=0)).reset_index(drop = True) \n",
    "    \n",
    "    ## expanding nested key_resp.rt values into separate columns, making new dataframe, and turning values back into floats from strings\n",
    "    stripped_rts_1 = ((df['key_resp_1.rt'].str.strip('[,]')).dropna()).str.split(',', expand = True)\n",
    "    stripped_rts_2 = ((df['key_resp_2.rt'].str.strip('[,]')).dropna()).str.split(',', expand = True)\n",
    "    rts_intocolumns = (pd.concat([stripped_rts_1, stripped_rts_2])).reset_index(drop = True)\n",
    "    \n",
    "    ## renames rt columns to automatically match dataset\n",
    "    DF = rts_intocolumns\n",
    "    renamed_rt = DF.rename(columns = { 0:'key_resp.rt.%s' %(0+1) })\n",
    "    for n in range(0, len(DF.columns)):\n",
    "        renamed_rt = renamed_rt.rename(columns = { n:'key_resp.rt.%s' %(n+1) })\n",
    "    expanded_rts = renamed_rt.astype(float).fillna(0) ##replacing NaNs with zeroes\n",
    "\n",
    "    ## expanding nested key_resp.keys values into separate columns and making new dataframe\n",
    "    stripped_keys_1 = ((df['key_resp_1.keys'].str.strip('[,]')).dropna()).str.split(',', expand = True)\n",
    "    stripped_keys_2 = ((df['key_resp_2.keys'].str.strip('[,]')).dropna()).str.split(',', expand = True)\n",
    "    keys_intocolumns = (pd.concat([stripped_keys_1, stripped_keys_2])).reset_index(drop = True)\n",
    "    keys_intocolumns = keys_intocolumns.where(pd.notnull(keys_intocolumns), None) \n",
    "        # ^ also replaces any added NaNs with Nones\n",
    "\n",
    "    ## renames key columns to automatically match dataset\n",
    "    DF = keys_intocolumns\n",
    "    expanded_keys = DF.rename(columns = { 0:'key_resp.keys.%s' %(0+1) })\n",
    "    for n in range(0, len(DF.columns)):\n",
    "        expanded_keys = expanded_keys.rename(columns = { n:'key_resp.keys.%s' %(n+1) })\n",
    "\n",
    "    ## getting rid of apostrophes and spaces in key values\n",
    "    cols_to_change = (expanded_keys.iloc[:, 0:])\n",
    "    for col in cols_to_change:\n",
    "        expanded_keys[col] = expanded_keys[col].str.replace(\"'\", \"\")\n",
    "        expanded_keys[col] = expanded_keys[col].str.replace(\" \", \"\")\n",
    "\n",
    "    ## combining key_resp.keys into one simple string to easily represent typed responses\n",
    "    responses_1 = pd.DataFrame((df['key_resp_1.keys'].str.replace(\"[', ]\", \"\", regex=True).str.strip(\"[]\")).dropna()).rename(columns = {'key_resp_1.keys':'resp_string'})\n",
    "    responses_2 = pd.DataFrame((df['key_resp_2.keys'].str.replace(\"[', ]\", \"\", regex=True).str.strip(\"[]\")).dropna()).rename(columns = {'key_resp_2.keys':'resp_string'})\n",
    "    responses = (pd.concat([responses_1, responses_2])).reset_index(drop = True)\n",
    "\n",
    "    ## identifying bigrams in words to add to larger dataframe\n",
    "    task_bigrams = pd.DataFrame(bi_allwords())\n",
    "    task_bigrams.columns = ['bi_1', 'bi_2', 'bi_3', 'bi_4']\n",
    "    \n",
    "    ## combining expanded rt, expanded keys, and response string values with column for strings typed each trial to create more useful dataframe\n",
    "    ## (does not have all the random timing data of other events occuring during the task)\n",
    "    main_df = pd.concat([responses, task_bigrams, expanded_keys, expanded_rts], axis = 1)\n",
    "    main_df.insert(0, 'string', df['string'], True)\n",
    "\n",
    "    ## creating column for WF type for each trial\n",
    "    main_df['wf_type'] = \"\"\n",
    "    for index, data in main_df.iterrows():\n",
    "        if main_df.loc[index, 'string'] in typ.highwf:\n",
    "            main_df.loc[index, 'wf_type'] = 'highwf'\n",
    "        if main_df.loc[index, 'string'] in typ.medwf:\n",
    "            main_df.loc[index, 'wf_type'] = 'medwf'\n",
    "        if main_df.loc[index, 'string'] in typ.lowwf:\n",
    "            main_df.loc[index, 'wf_type'] = 'lowwf'\n",
    "        if main_df.loc[index, 'string'] in typ.pseudo:\n",
    "            main_df.loc[index, 'wf_type'] = 'pseudo'\n",
    "\n",
    "    ## creating column for BF type for each trial\n",
    "    main_df['meanbf_type'] = \"\"\n",
    "    for index, data in main_df.iterrows():\n",
    "        if main_df.loc[index, 'string'] in typ.avg_highbf:\n",
    "            main_df.loc[index, 'meanbf_type'] = 'highbf'\n",
    "        if main_df.loc[index, 'string'] in typ.avg_medbf:\n",
    "            main_df.loc[index, 'meanbf_type'] = 'medbf'\n",
    "        if main_df.loc[index, 'string'] in typ.avg_lowbf:\n",
    "            main_df.loc[index, 'meanbf_type'] = 'lowbf'\n",
    "\n",
    "    ## creating column for trial (useful for group analysis)\n",
    "    trial_nums = []\n",
    "    for index, data in main_df.iterrows():\n",
    "        trial_nums.append(index)\n",
    "    main_df.insert(0, 'trial_num', trial_nums)\n",
    "\n",
    "    ## creating column for subject ID (also useful for group analysis)\n",
    "    main_ID = [sID]*len(main_df)\n",
    "    main_df.insert(0, 'sID', main_ID)\n",
    "\n",
    "    ## creating columns for word repetition number\n",
    "    main_df.insert(2, 'rep_num', '')\n",
    "    main_df['rep_num'] = main_df.groupby(['sID', 'string']).cumcount()\n",
    "    \n",
    "    ## making csv from dataframe\n",
    "    edited_path = os.path.join(sub_folder, 'edited')\n",
    "    if os.path.exists(edited_path) == False:\n",
    "        os.mkdir(edited_path)\n",
    "    bytrial_path = os.path.join(edited_path, '%s_bytrial.csv' % sID)\n",
    "    print(bytrial_path)\n",
    "    main_df.to_csv(bytrial_path)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ## BIGRAM DATAFRAME ##\n",
    "    bigram_df = (pd.DataFrame(bigram_byrow())).rename(columns={0: \"trial_num\", 1: \"bigram_loc\",  2:\"resp_bigram\", 3: \"IKI\", 4: \"string\", 5: \"resp_string\"})\n",
    "\n",
    "    ## creating column for bigram # (useful for group analysis)\n",
    "    bigram_nums = []\n",
    "    for index, data in bigram_df.iterrows():\n",
    "        bigram_nums.append(index)\n",
    "    bigram_df.insert(0, 'bigram_num', bigram_nums)\n",
    "\n",
    "    ## creating column for subject ID (also useful for group analysis)\n",
    "    bigram_ID = [sID]*len(bigram_df)\n",
    "    bigram_df.insert(0, 'sID', bigram_ID)\n",
    "\n",
    "    ## creating column for correct bigram (as opposed to the typed bigram)\n",
    "    bigram_df.insert(4, 'bigram', '')\n",
    "    for index, row in bigram_df.iterrows():\n",
    "        loc = bigram_df.loc[index, 'bigram_loc']\n",
    "        loc_list = [0, 1, 2, 3]\n",
    "        if loc in loc_list:\n",
    "            corr = bi_byword(bigram_df.loc[index, 'string'])[loc]\n",
    "        else:\n",
    "            corr = ''\n",
    "        bigram_df.loc[index, 'bigram'] = corr\n",
    "\n",
    "    ## creating column for rep #\n",
    "    bigram_df.insert(3, 'rep_num', '')\n",
    "    bigram_df['rep_num'] = bigram_df.groupby(['sID', 'string', 'bigram']).cumcount()\n",
    "    \n",
    "    ## creating column for bigram frequency\n",
    "    bg_freqs = pd.read_csv(r'/Users/rubi/Desktop/Github/typingexp/typing_task_analysis/bg_freqs.csv') ## EDIT TO MAKE USEFUL ON OTHER COMPUTERS\n",
    "    bg_freqs.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "    freq_dict = bg_freqs.set_index('Bigrams')['Frequency'].to_dict()\n",
    "    bigram_df['bg_freq'] = bigram_df['bigram'].map(freq_dict)\n",
    "\n",
    "    ## creating column for bigram type\n",
    "    name_list = ['high', 'med', 'low', 'pseudo']\n",
    "\n",
    "    for index, bf_type in enumerate(typ.bf_types):\n",
    "        by_bf = bigram_df[bigram_df.bigram.isin(bf_type)]\n",
    "        rows = by_bf.index\n",
    "        bigram_df.loc[rows, 'bf_type'] = name_list[index]\n",
    "\n",
    "    ## creating a column for mean bigram type\n",
    "    for index, avgbf_type in enumerate(typ.avgbf_types):\n",
    "        by_bf = bigram_df[bigram_df.string.isin(avgbf_type)]\n",
    "        rows = by_bf.index\n",
    "        bigram_df.loc[rows, 'meanbf_type'] = name_list[index]\n",
    "\n",
    "    ## creating a column for mean bigram type\n",
    "    for index, wf_type in enumerate(typ.wf_types):\n",
    "        by_wf = bigram_df[bigram_df.string.isin(wf_type)]\n",
    "        rows = by_wf.index\n",
    "        bigram_df.loc[rows, 'wf_type'] = name_list[index]\n",
    "\n",
    "    ## making csv from dataframe\n",
    "    bybigram_path = os.path.join(edited_path, '%s_bybigram.csv' % sID)\n",
    "    print(bybigram_path)\n",
    "    bigram_df.to_csv(bybigram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sID</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>rep_num</th>\n",
       "      <th>string</th>\n",
       "      <th>resp_string</th>\n",
       "      <th>bi_1</th>\n",
       "      <th>bi_2</th>\n",
       "      <th>bi_3</th>\n",
       "      <th>bi_4</th>\n",
       "      <th>key_resp.keys.1</th>\n",
       "      <th>...</th>\n",
       "      <th>key_resp.keys.7</th>\n",
       "      <th>key_resp.rt.1</th>\n",
       "      <th>key_resp.rt.2</th>\n",
       "      <th>key_resp.rt.3</th>\n",
       "      <th>key_resp.rt.4</th>\n",
       "      <th>key_resp.rt.5</th>\n",
       "      <th>key_resp.rt.6</th>\n",
       "      <th>key_resp.rt.7</th>\n",
       "      <th>wf_type</th>\n",
       "      <th>meanbf_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>wo</td>\n",
       "      <td>ou</td>\n",
       "      <td>ul</td>\n",
       "      <td>ld</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.723308</td>\n",
       "      <td>0.827496</td>\n",
       "      <td>0.915393</td>\n",
       "      <td>1.051286</td>\n",
       "      <td>1.091396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>highwf</td>\n",
       "      <td>medbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>vodka</td>\n",
       "      <td>vodka</td>\n",
       "      <td>vo</td>\n",
       "      <td>od</td>\n",
       "      <td>dk</td>\n",
       "      <td>ka</td>\n",
       "      <td>v</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.165449</td>\n",
       "      <td>1.285454</td>\n",
       "      <td>1.405452</td>\n",
       "      <td>1.525459</td>\n",
       "      <td>1.589452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medwf</td>\n",
       "      <td>lowbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s217</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>kremp</td>\n",
       "      <td>kremp</td>\n",
       "      <td>kr</td>\n",
       "      <td>re</td>\n",
       "      <td>em</td>\n",
       "      <td>mp</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.033510</td>\n",
       "      <td>1.113516</td>\n",
       "      <td>1.201451</td>\n",
       "      <td>1.249445</td>\n",
       "      <td>1.385430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>medbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s217</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>theme</td>\n",
       "      <td>theme</td>\n",
       "      <td>th</td>\n",
       "      <td>he</td>\n",
       "      <td>em</td>\n",
       "      <td>me</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.741364</td>\n",
       "      <td>0.837475</td>\n",
       "      <td>0.877338</td>\n",
       "      <td>1.029368</td>\n",
       "      <td>1.093365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medwf</td>\n",
       "      <td>highbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s217</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>druze</td>\n",
       "      <td>druze</td>\n",
       "      <td>dr</td>\n",
       "      <td>ru</td>\n",
       "      <td>uz</td>\n",
       "      <td>ze</td>\n",
       "      <td>d</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.793336</td>\n",
       "      <td>0.985552</td>\n",
       "      <td>1.153500</td>\n",
       "      <td>1.241438</td>\n",
       "      <td>1.385341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lowwf</td>\n",
       "      <td>lowbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>s217</td>\n",
       "      <td>235</td>\n",
       "      <td>9</td>\n",
       "      <td>cheer</td>\n",
       "      <td>cheer</td>\n",
       "      <td>ch</td>\n",
       "      <td>he</td>\n",
       "      <td>ee</td>\n",
       "      <td>er</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.605839</td>\n",
       "      <td>0.749859</td>\n",
       "      <td>0.845765</td>\n",
       "      <td>1.021899</td>\n",
       "      <td>1.101868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medwf</td>\n",
       "      <td>highbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>s217</td>\n",
       "      <td>236</td>\n",
       "      <td>9</td>\n",
       "      <td>heond</td>\n",
       "      <td>heond</td>\n",
       "      <td>he</td>\n",
       "      <td>eo</td>\n",
       "      <td>on</td>\n",
       "      <td>nd</td>\n",
       "      <td>h</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770076</td>\n",
       "      <td>0.882104</td>\n",
       "      <td>0.970067</td>\n",
       "      <td>1.074068</td>\n",
       "      <td>1.201988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>highbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>s217</td>\n",
       "      <td>237</td>\n",
       "      <td>9</td>\n",
       "      <td>lucky</td>\n",
       "      <td>lucky</td>\n",
       "      <td>lu</td>\n",
       "      <td>uc</td>\n",
       "      <td>ck</td>\n",
       "      <td>ky</td>\n",
       "      <td>l</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.670279</td>\n",
       "      <td>0.894252</td>\n",
       "      <td>1.054194</td>\n",
       "      <td>1.198233</td>\n",
       "      <td>1.430445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>highwf</td>\n",
       "      <td>lowbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>s217</td>\n",
       "      <td>238</td>\n",
       "      <td>9</td>\n",
       "      <td>about</td>\n",
       "      <td>about</td>\n",
       "      <td>ab</td>\n",
       "      <td>bo</td>\n",
       "      <td>ou</td>\n",
       "      <td>ut</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.681711</td>\n",
       "      <td>0.801726</td>\n",
       "      <td>1.081651</td>\n",
       "      <td>1.193738</td>\n",
       "      <td>1.337723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>highwf</td>\n",
       "      <td>medbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>s217</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>ch</td>\n",
       "      <td>ha</td>\n",
       "      <td>am</td>\n",
       "      <td>mp</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.774146</td>\n",
       "      <td>0.870122</td>\n",
       "      <td>0.974140</td>\n",
       "      <td>1.102104</td>\n",
       "      <td>1.254125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medwf</td>\n",
       "      <td>medbf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sID  trial_num  rep_num string resp_string bi_1 bi_2 bi_3 bi_4  \\\n",
       "0    s217          0        0  would       would   wo   ou   ul   ld   \n",
       "1    s217          1        0  vodka       vodka   vo   od   dk   ka   \n",
       "2    s217          2        0  kremp       kremp   kr   re   em   mp   \n",
       "3    s217          3        0  theme       theme   th   he   em   me   \n",
       "4    s217          4        0  druze       druze   dr   ru   uz   ze   \n",
       "..    ...        ...      ...    ...         ...  ...  ...  ...  ...   \n",
       "235  s217        235        9  cheer       cheer   ch   he   ee   er   \n",
       "236  s217        236        9  heond       heond   he   eo   on   nd   \n",
       "237  s217        237        9  lucky       lucky   lu   uc   ck   ky   \n",
       "238  s217        238        9  about       about   ab   bo   ou   ut   \n",
       "239  s217        239        9  champ       champ   ch   ha   am   mp   \n",
       "\n",
       "    key_resp.keys.1  ... key_resp.keys.7 key_resp.rt.1 key_resp.rt.2  \\\n",
       "0                 w  ...            None      0.723308      0.827496   \n",
       "1                 v  ...            None      1.165449      1.285454   \n",
       "2                 k  ...            None      1.033510      1.113516   \n",
       "3                 t  ...            None      0.741364      0.837475   \n",
       "4                 d  ...            None      0.793336      0.985552   \n",
       "..              ...  ...             ...           ...           ...   \n",
       "235               c  ...            None      0.605839      0.749859   \n",
       "236               h  ...            None      0.770076      0.882104   \n",
       "237               l  ...            None      0.670279      0.894252   \n",
       "238               a  ...            None      0.681711      0.801726   \n",
       "239               c  ...            None      0.774146      0.870122   \n",
       "\n",
       "    key_resp.rt.3 key_resp.rt.4 key_resp.rt.5  key_resp.rt.6  key_resp.rt.7  \\\n",
       "0        0.915393      1.051286      1.091396            0.0            0.0   \n",
       "1        1.405452      1.525459      1.589452            0.0            0.0   \n",
       "2        1.201451      1.249445      1.385430            0.0            0.0   \n",
       "3        0.877338      1.029368      1.093365            0.0            0.0   \n",
       "4        1.153500      1.241438      1.385341            0.0            0.0   \n",
       "..            ...           ...           ...            ...            ...   \n",
       "235      0.845765      1.021899      1.101868            0.0            0.0   \n",
       "236      0.970067      1.074068      1.201988            0.0            0.0   \n",
       "237      1.054194      1.198233      1.430445            0.0            0.0   \n",
       "238      1.081651      1.193738      1.337723            0.0            0.0   \n",
       "239      0.974140      1.102104      1.254125            0.0            0.0   \n",
       "\n",
       "     wf_type  meanbf_type  \n",
       "0     highwf        medbf  \n",
       "1      medwf        lowbf  \n",
       "2     pseudo        medbf  \n",
       "3      medwf       highbf  \n",
       "4      lowwf        lowbf  \n",
       "..       ...          ...  \n",
       "235    medwf       highbf  \n",
       "236   pseudo       highbf  \n",
       "237   highwf        lowbf  \n",
       "238   highwf        medbf  \n",
       "239    medwf        medbf  \n",
       "\n",
       "[240 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can also be specified\n",
    "#     print(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sID</th>\n",
       "      <th>bigram_num</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>rep_num</th>\n",
       "      <th>bigram_loc</th>\n",
       "      <th>bigram</th>\n",
       "      <th>resp_bigram</th>\n",
       "      <th>IKI</th>\n",
       "      <th>string</th>\n",
       "      <th>resp_string</th>\n",
       "      <th>bg_freq</th>\n",
       "      <th>bf_type</th>\n",
       "      <th>meanbf_type</th>\n",
       "      <th>wf_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wo</td>\n",
       "      <td>wo</td>\n",
       "      <td>0.104188</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>1723496.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ou</td>\n",
       "      <td>ou</td>\n",
       "      <td>0.087897</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>7425307.0</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s217</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ul</td>\n",
       "      <td>ul</td>\n",
       "      <td>0.135893</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>2181271.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s217</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>ld</td>\n",
       "      <td>ld</td>\n",
       "      <td>0.040110</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>2012500.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s217</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>vo</td>\n",
       "      <td>vo</td>\n",
       "      <td>0.120005</td>\n",
       "      <td>vodka</td>\n",
       "      <td>vodka</td>\n",
       "      <td>368238.0</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>s217</td>\n",
       "      <td>960</td>\n",
       "      <td>238</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>ut</td>\n",
       "      <td>ut</td>\n",
       "      <td>0.143985</td>\n",
       "      <td>about</td>\n",
       "      <td>about</td>\n",
       "      <td>3257233.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>s217</td>\n",
       "      <td>961</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>ch</td>\n",
       "      <td>ch</td>\n",
       "      <td>0.095976</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>3267507.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>s217</td>\n",
       "      <td>962</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>ha</td>\n",
       "      <td>ha</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>6967591.0</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>s217</td>\n",
       "      <td>963</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>am</td>\n",
       "      <td>am</td>\n",
       "      <td>0.127965</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>1610395.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>s217</td>\n",
       "      <td>964</td>\n",
       "      <td>239</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.152021</td>\n",
       "      <td>champ</td>\n",
       "      <td>champ</td>\n",
       "      <td>1042198.0</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sID  bigram_num  trial_num  rep_num  bigram_loc bigram resp_bigram  \\\n",
       "0    s217           0          0        0           0     wo          wo   \n",
       "1    s217           1          0        0           1     ou          ou   \n",
       "2    s217           2          0        0           2     ul          ul   \n",
       "3    s217           3          0        0           3     ld          ld   \n",
       "4    s217           4          1        0           0     vo          vo   \n",
       "..    ...         ...        ...      ...         ...    ...         ...   \n",
       "960  s217         960        238        9           3     ut          ut   \n",
       "961  s217         961        239        9           0     ch          ch   \n",
       "962  s217         962        239        9           1     ha          ha   \n",
       "963  s217         963        239        9           2     am          am   \n",
       "964  s217         964        239        9           3     mp          mp   \n",
       "\n",
       "          IKI string resp_string    bg_freq bf_type meanbf_type wf_type  \n",
       "0    0.104188  would       would  1723496.0     med         med    high  \n",
       "1    0.087897  would       would  7425307.0    high         med    high  \n",
       "2    0.135893  would       would  2181271.0     med         med    high  \n",
       "3    0.040110  would       would  2012500.0     med         med    high  \n",
       "4    0.120005  vodka       vodka   368238.0     low         low     med  \n",
       "..        ...    ...         ...        ...     ...         ...     ...  \n",
       "960  0.143985  about       about  3257233.0     med         med    high  \n",
       "961  0.095976  champ       champ  3267507.0     med         med     med  \n",
       "962  0.104018  champ       champ  6967591.0    high         med     med  \n",
       "963  0.127965  champ       champ  1610395.0     med         med     med  \n",
       "964  0.152021  champ       champ  1042198.0     med         med     med  \n",
       "\n",
       "[965 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can also be specified\n",
    "#     print(bigram_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
