{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c309bf7e-ce49-424e-a3a4-fb574fe77897",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script to analyze Turbo Typing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd97497-a0a2-416c-9052-9c794c4bcb30",
   "metadata": {},
   "source": [
    "Notes on where I'm leaving off:   \n",
    "- 9/22/24 Just wrote code that removes the extra spaces before characters from the imported data without deleting actual spaces. Next I want to use the collapsed sentences with no extra s\n",
    "- spaces to use the diff function and compare them.  \n",
    "- 9/23/2024 Basically same goal for next time. I had to make a new column that replaces the multi-character key names with special characters for the keyData from the participants, which was completed today.\n",
    "- 9/24/2024 Isolated correct keypress times. Next time, calculate ttk for correct presses, mean ttk, and the rest of the assessment variables. Also ask Patrick the best way to organize and write code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370be61e-9229-4a17-bf73-2dfce548a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import editdistance\n",
    "from scipy import stats\n",
    "import diff_match_patch as dmp_module\n",
    "dmp = dmp_module.diff_match_patch()\n",
    "import copy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import variation\n",
    "import typingmod as typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7dd799-a6ab-47a7-b2fa-1dc8e274e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imported data from Turbo Typing stores listed data as a long string. \n",
    "# This splits it up into actual lists.\n",
    "def str_to_list(dataframe, columns):\n",
    "    for col in columns:\n",
    "        data_str = dataframe[col]\n",
    "        if type(data_str.iloc[0]) == list:\n",
    "            pass\n",
    "        elif type(data_str.iloc[0]) == str:\n",
    "            if data_str.iloc[0][0].isdigit() == True:\n",
    "                data_list = data_str.apply(lambda trial: \n",
    "                                           [int(char) for char in trial.split(',')])\n",
    "                dataframe[col] = data_list\n",
    "            elif data_str.iloc[0][0].isdigit() == False:\n",
    "                data_list = [x.split(',') for x in data_str]\n",
    "                dataframe[col] = data_list\n",
    "        else:\n",
    "            print('Column must have data in string form.')\n",
    "\n",
    "# Removes extra spaces before characters in keypress data.\n",
    "def no_extra_spaces(dataframe, columns):\n",
    "    for col in columns:\n",
    "        no_space = dataframe[col].apply(lambda trial: \n",
    "                                        [char.replace(\" \",\"\") if char.isspace() \n",
    "                                         != True else ' ' for char in trial])\n",
    "        dataframe[col] = no_space\n",
    "\n",
    "# Changes multi-chracter keynames (ie. LeftShift and Backspace) to special\n",
    "# characters.\n",
    "def multi_to_special(dataframe, column):\n",
    "    data = dataframe[column]\n",
    "    edit_data = []\n",
    "    for trial in data:\n",
    "        edit_trial = copy.deepcopy(trial) # Pandas can't deep copy lists in dataframes, so this is a work around.\n",
    "        for index, key in enumerate(edit_trial):\n",
    "            if len(key) == 1:\n",
    "                pass\n",
    "            if len(key) > 1:\n",
    "                if key in ['LeftShift', 'RightShift']:\n",
    "                    edit_trial[index] = '#'\n",
    "                elif key == 'Backspace':\n",
    "                    edit_trial[index] = '-'\n",
    "                elif key == 'Return':\n",
    "                    edit_trial[index] = '^'\n",
    "                else:\n",
    "                    edit_trial[index] = '~' # '~' replaces any other keys longer than one character.\n",
    "        edit_data.append(edit_trial)\n",
    "    return edit_data\n",
    "\n",
    "# Calculates time to keypress (TTK) for all presses in one trial.\n",
    "# TTK is the reaction time for the first press and the interkey \n",
    "# interval for any subsequent presses.\n",
    "def ttk(row, column):\n",
    "    presses = pd.DataFrame(row.loc[column])\n",
    "    ttk_df = presses.sub(presses.shift(fill_value=0))\n",
    "    ttk_list = ttk_df.values.flatten().tolist()\n",
    "    return ttk_list\n",
    "\n",
    "# Creates a list of keys that would have been pressed if the sentence was typed\n",
    "# with no errors (ie. no backspacing). Uses single, special characters to \n",
    "# represent multi-character key names (ie. '^' for 'Return').\n",
    "def sentence_to_keydata(string):\n",
    "    curr_keyData = []\n",
    "    for index, data in enumerate(string):\n",
    "        if data.isupper() == True:\n",
    "            curr_keyData.append('#') # '#' Replaces 'Right/LeftShift'\n",
    "            curr_keyData.append(data)\n",
    "        elif data.isupper() == False and data.isalpha() or data.isspace() == True:\n",
    "            curr_keyData.append(data)\n",
    "        elif data == '?':\n",
    "            curr_keyData.append('#')\n",
    "            curr_keyData.append(data)\n",
    "            curr_keyData.append('^')\n",
    "        elif data == '.':\n",
    "            curr_keyData.append(data)\n",
    "            curr_keyData.append('^') # '^' Replaces 'Return'\n",
    "    return curr_keyData\n",
    "\n",
    "# # Splits up keyDataConverted data from a string to a list of pressed keys.\n",
    "# def split_str(row):\n",
    "#     keys_str = row.loc['keyDataConverted']\n",
    "#     keys_list = keys_str.split(',')\n",
    "#     return keys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950ab28b-75e2-40a6-ba72-c1d9bd2b30f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rubi/Desktop/Github/typingexp/typing_task_analysis/figures'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting save directory\n",
    "save_dir = r'/Users/rubi/Desktop/Github/typingexp/typing_task_analysis/'\\\n",
    "           'figures'\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf7778e-51f4-4431-88d6-316d9adfbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting subject data folders from server.\n",
    "server = r'/Volumes/greenhouse/typingtask_data/subject_data'\n",
    "os.chdir(server)\n",
    "folders = os.listdir()\n",
    "\n",
    "# Looping through subject folders, getting appropriate paths to data, \n",
    "# and making sID list.\n",
    "sub_folders = list(filter(lambda x: x.startswith('s', 0, 1), folders))\n",
    "all_turbo = pd.DataFrame()\n",
    "ID_list = []\n",
    "for sub in sub_folders:\n",
    "    sub_folder = r'/Volumes/greenhouse/typingtask_data/'\\\n",
    "                 'subject_data/%s/turbotyping_data' % sub\n",
    "    os.chdir(sub_folder)\n",
    "    sID = sub.split('_', 1)[0]\n",
    "    turbo = pd.read_csv(glob.glob('*_datafile.tsv')[0], sep='\\t')\n",
    "    all_turbo = pd.concat([all_turbo, turbo])\n",
    "    ID_list.append(sID)\n",
    "\n",
    "all_turbo = all_turbo.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629fe343-2a4b-41af-bf13-c5e1ecef4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s262',\n",
       " 's261',\n",
       " 's240',\n",
       " 's217',\n",
       " 's176',\n",
       " 's267',\n",
       " 's263',\n",
       " 's254',\n",
       " 's209',\n",
       " 's276',\n",
       " 's278',\n",
       " 's279',\n",
       " 's282',\n",
       " 's283',\n",
       " 's286',\n",
       " 's302',\n",
       " 's304',\n",
       " 's306',\n",
       " 's305',\n",
       " 's309',\n",
       " 's311',\n",
       " 's009',\n",
       " 's020',\n",
       " 's207',\n",
       " 's313']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141198b0-e503-4c3b-8f30-265c5d6d8f8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transforms listed data stored in long strings to actual lists.\n",
    "str_to_list(all_turbo, ['timeData', \n",
    "                        'keyData', \n",
    "                        'keyDataConverted', \n",
    "                        'timeDataUp',\n",
    "                        'keyDataUp'])\n",
    "\n",
    "# Removes extra spaces before characters in keypress data columns.\n",
    "no_extra_spaces(all_turbo, ['keyData', 'keyDataConverted', 'keyDataUp'])\n",
    "\n",
    "# Replaces multi-character key names with single, special characters from key\n",
    "# press data typed by participants. \n",
    "no_multichar_keys = multi_to_special(all_turbo, 'keyDataConverted')\n",
    "all_turbo.insert(11, 'keyDataSpecialChar', no_multichar_keys)\n",
    "\n",
    "# Creates column that represents the correct key press sequence if there were\n",
    "# no errors (uses special characters for multi-character key names).\n",
    "current_keyData = [sentence_to_keydata(x) for x in all_turbo['currentSentence']]\n",
    "all_turbo.insert(8, 'keyDataCurrent', current_keyData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d124369f-1006-445f-9d7c-86951598c35e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compares the correct sequence of keypresses with what was typed during the \n",
    "# trial and returns the difference between the two.\n",
    "string_diff = all_turbo.apply(lambda row: \n",
    "                            dmp.diff_main(''.join(row.loc['keyDataSpecialChar']), \n",
    "                                          ''.join(row.loc['keyDataCurrent'])),\n",
    "                            axis=1)\n",
    "\n",
    "# Separates the returned differences into individual characters.\n",
    "diffs_bychar = []\n",
    "for trial in string_diff:\n",
    "    diff_bychar_trial = []\n",
    "    for diff in trial:\n",
    "        if len(diff[1]) == 1:\n",
    "            diff_bychar_trial.append([diff[0], diff[1]])\n",
    "        elif len(diff[1]) > 1:\n",
    "            for char in diff[1]:\n",
    "                diff_bychar_trial.append([diff[0], char])\n",
    "    diffs_bychar.append(diff_bychar_trial)\n",
    "\n",
    "# Differences for errors where participants swap two letters are solved as: \n",
    "# letter 2 subtraction, letter 1 retention, letter 2 addition. Because  \n",
    "# both letters 1 and 2 need to be identified as incorrect keypresses, this code \n",
    "# changes the difference to show: letter 2 subtraction, letter 1 subtraction.\n",
    "diffs_bychar_fixswap = []\n",
    "for trial in diffs_bychar:\n",
    "    chardiffs_trial = []\n",
    "    char_toskip = 0\n",
    "    for index, char in enumerate(trial):\n",
    "        if char_toskip != 0:\n",
    "            char_toskip = char_toskip - 1\n",
    "            continue\n",
    "        if char[0] == 0:\n",
    "            if index == (len(trial) - 1) or index == 0:\n",
    "                chardiffs_trial.append(char)\n",
    "            else:\n",
    "                if trial[index - 1][0] == -1 and trial[index + 1][0] == 1:\n",
    "                    if trial[index - 1][1] == trial[index + 1][1]:\n",
    "                        chardiffs_trial.append([-1, char[1]])\n",
    "                        char_toskip = 1\n",
    "                else:\n",
    "                    chardiffs_trial.append(char)\n",
    "        else:\n",
    "            chardiffs_trial.append(char)\n",
    "    diffs_bychar_fixswap.append(chardiffs_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92db6882-4fe8-4cca-b5e4-ffa279f0bd4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Isolates characters and indices in original keyData/timeData lists for correct \n",
    "# keypresses and adds both to new columns.\n",
    "corr_keys = []\n",
    "corr_indices = []\n",
    "for trial in diffs_bychar_fixswap:\n",
    "    corr_keys_trial = []\n",
    "    corr_indices_trial = []\n",
    "    for index, char in enumerate(trial):\n",
    "        if char[0] == 0:\n",
    "            corr_keys_trial.append(char[1])\n",
    "            corr_indices_trial.append(index)\n",
    "        else:\n",
    "            pass\n",
    "    corr_keys.append(corr_keys_trial)\n",
    "    corr_indices.append(corr_indices_trial)\n",
    "    \n",
    "all_turbo.insert(12, 'keyDataCorrect', corr_keys)\n",
    "all_turbo.insert(13, 'keyIndicesCorrect', corr_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a1b5be-7541-4e7f-8ea3-a041e6c474d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Isolates keypress times for correct keypresses and adds to a new column.\n",
    "def corr_time(trial):\n",
    "    times = trial.loc['timeData']\n",
    "    indices = trial.loc['keyIndicesCorrect']\n",
    "    matched_indices =[]\n",
    "    for index, time in enumerate(times):\n",
    "        if index in indices:\n",
    "            matched_indices.append(time)\n",
    "    return matched_indices\n",
    "\n",
    "corr_times = all_turbo.apply(corr_time, axis=1)\n",
    "all_turbo.insert(10, 'timeDataCorrect', corr_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c5e47e8-a176-49fa-815b-6986f0f64e7b",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculates edit distance of each trial and stores to an additional column.\n",
    "edit_dist = all_turbo.apply(lambda row: \n",
    "                            editdistance.eval(row.loc['currentSentence'], \n",
    "                                              row.loc['typedSentence']), \n",
    "                            axis=1)\n",
    "all_turbo['editDistance'] = edit_dist\n",
    "\n",
    "# Calculates TTK for every character typed in each trial and stores to \n",
    "# an additional column.\n",
    "ttks = all_turbo.apply(lambda row: ttk(row, 'timeData'), axis=1)\n",
    "all_turbo['ttk'] = ttks\n",
    "\n",
    "# Calculates TTK for every character correctly typed in each trial and stores to \n",
    "# an additional column.\n",
    "ttks_corr = all_turbo.apply(lambda row: ttk(row, 'timeDataCorrect'), axis=1)\n",
    "all_turbo['ttkCorrect'] = ttks_corr\n",
    "\n",
    "# Calculates mean TTK for each trial and stores to an additional column.\n",
    "mean_ttk = [np.mean(x) for x in all_turbo['ttk']]\n",
    "all_turbo['ttkMean'] = mean_ttk\n",
    "\n",
    "# Calculates mean correct TTK for each trial and stores to an additional column.\n",
    "mean_ttk_corr = [np.mean(x) for x in all_turbo['ttkCorrect']]\n",
    "all_turbo['ttkMeanCorrect'] = mean_ttk_corr\n",
    "\n",
    "# Calculates sum of all TTKs for each trial and stores to an additional column.\n",
    "sum_ttk = [np.sum(x) for x in all_turbo['ttk']]\n",
    "all_turbo['ttkSum'] = sum_ttk\n",
    "all_turbo['ttkMean']\n",
    "\n",
    "# Calculates sum of all correct TTKs for each trial and stores to an additional \n",
    "# column.\n",
    "sum_ttk_corr = [np.sum(x) for x in all_turbo['ttkCorrect']]\n",
    "all_turbo['ttkSumCorrect'] = sum_ttk_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b22fe4a2-756e-4f86-8ae1-7b42726d3bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculates IES\n",
    "def ies(row):\n",
    "    mean_corr_rt = row['ttkMeanCorrect']\n",
    "    pc = len(row['ttkCorrect'])/len(row['ttk'])\n",
    "    return mean_corr_rt/pc\n",
    "\n",
    "ies = all_turbo.apply(lambda row: ies(row), \n",
    "                      axis=1)\n",
    "all_turbo['ies'] = ies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd1695d4-12a4-46e5-8e0b-603516c4bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates rate correct score (RCS) for each trial and stores in column.\n",
    "rcs = all_turbo.apply(lambda row: \n",
    "                      len(row.loc['ttkCorrect'])/row.loc['ttkSum'],\n",
    "                      axis=1)\n",
    "all_turbo['rcs'] = rcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a98b5f36-0c85-463e-803e-2682becf4b13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/sqkdrmx52wgfnxt8ycz1hhlc0000gn/T/ipykernel_61601/268902196.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return rt_mean + (np.std(rt_mean)/pe_std)*pe\n"
     ]
    }
   ],
   "source": [
    "# Calculates linear integrated speed-ccuracy score (LISAS) and stores in column.\n",
    "def lisas(row):\n",
    "    rt_mean = row.loc['ttkMeanCorrect']\n",
    "    rt_std = np.std(row.loc['ttkCorrect'])\n",
    "    pe = 1-(len(row['ttkCorrect'])/len(row['ttk']))\n",
    "    pe_std = np.sqrt(pe*(1-pe))\n",
    "    return rt_mean + (np.std(rt_mean)/pe_std)*pe\n",
    "\n",
    "lisas_output = all_turbo.apply(lambda row: lisas(row), axis=1)\n",
    "all_turbo['lisas'] = lisas_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97197940-df8a-45da-b15a-e916d7253cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Calculates BIS\n",
    "# # by_sub = all_turbo.groupby('participantID')\n",
    "# z_score = stats.zscore\n",
    "# # by_sub = pd.DataFrame(all_turbo.groupby('participantID').filter(lambda x: print(x['trialNumber'])))\n",
    "# ttkmean_bysub = pd.DataFrame(all_turbo[all_turbo['trialNumber'] >= 0].groupby('participantID').ttkMean)\n",
    "# # totalttkmean_bysub = ttkmean_bysub\n",
    "# # by_sub = by_sub.reset_index().rename(columns = {'ttk':'all_ttk'})\n",
    "# # ttkmean_bysub\n",
    "# # test = ttkmean_bysub.\n",
    "# # test = ttkmean_bysub[1][0].mean()\n",
    "# # test\n",
    "# test = ttkmean_bysub[1].apply(lambda x: stats.zscore(x))\n",
    "# # stats.zscore(ttkmean_bysub[1][0])\n",
    "# # ttkmean_bysub\n",
    "# # by_sub[1][0]\n",
    "# # test\n",
    "# # by_sub['all_ttk'].apply(stats.zscore)\n",
    "# test = test.transpose()\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcb38824-83e6-41bd-8643-3d5142368e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rubi/miniconda3/envs/jlab/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rubi/miniconda3/envs/jlab/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rubi/miniconda3/envs/jlab/lib/python3.12/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/rubi/miniconda3/envs/jlab/lib/python3.12/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/Users/rubi/miniconda3/envs/jlab/lib/python3.12/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Isolates keypress times for correctly typed alphabet characters (a-z) and adds \n",
    "# to a new column.\n",
    "def alpha_time(row):\n",
    "    trial = row.loc['keyDataCorrect']\n",
    "    times = row.loc['timeData']\n",
    "    alpha_indices = [index for (index, char) in enumerate(trial) if char.isalpha() == True]\n",
    "    alpha_time = [time for (index, time) in enumerate(times) if index in alpha_indices]\n",
    "    return alpha_time\n",
    "\n",
    "alpha_times = all_turbo.apply(alpha_time, axis=1)\n",
    "all_turbo.insert(11, 'timeDataAlpha', alpha_times)\n",
    "\n",
    "# Calculates IKI (excludes first TTK) for correctly typed alphabet characters \n",
    "# (a-z) in each trial and stores to a new column.\n",
    "ttks_alpha = all_turbo.apply(lambda row: ttk(row, 'timeDataAlpha'), axis=1)\n",
    "ikis_alpha = [ttk[1:] for ttk in ttks_alpha]\n",
    "all_turbo['ikiAlpha'] = ikis_alpha\n",
    "\n",
    "# Calculates mean IKI for each trial and stores to new column. \n",
    "all_turbo['meanikiAlpha'] = [np.mean(ikis) for ikis in all_turbo.ikiAlpha]\n",
    "all_turbo['sdikiAlpha'] = [np.std(ikis) for ikis in all_turbo.ikiAlpha]\n",
    "all_turbo['cvikiAlpha'] = [variation(ikis) for ikis in all_turbo.ikiAlpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "153d52cc-be25-4978-8e44-370473e34997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates individual Mean IKI for correctly typed alphabet characters.\n",
    "meanikis_alpha = all_turbo.groupby('participantID').meanikiAlpha.agg('mean').reset_index()\n",
    "\n",
    "# Divides values by 1000 to put on same scale as mean IKIs from in-house typing\n",
    "# task. \n",
    "def divby1000(value):\n",
    "    return value/1000\n",
    "meanikis_alpha['meanikiAlpha'] = meanikis_alpha.meanikiAlpha.transform(divby1000)\n",
    "# meanikis_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "165d7281-e7f7-4d2f-bd29-d94d45535e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe of subject score averages for each IES, RCS, and LISAS.\n",
    "subject_scores = pd.DataFrame()\n",
    "subject_scores['sID'] = ID_list\n",
    "subject_scores = subject_scores.sort_values(by=['sID']).reset_index(drop = True)\n",
    "\n",
    "# Adding mean IES scores.\n",
    "mean_ies = all_turbo.groupby('participantID').ies.agg(['mean'])\n",
    "mean_ies = mean_ies.sort_values(by=['participantID'])\n",
    "subject_scores['mean_ies'] = mean_ies.reset_index()['mean']\n",
    "\n",
    "# Adding mean IKIs for alphabetic characters.\n",
    "meanikis_alpha = all_turbo.groupby('participantID').meanikiAlpha.agg('mean').reset_index()\n",
    "def divby1000(value): # Divides values by 1000 to put on same scale as mean IKIs  \n",
    "    return value/1000 # from in-house typing task.\n",
    "meanikis_alpha['meanikiAlpha'] = meanikis_alpha.meanikiAlpha.transform(divby1000)\n",
    "meanikis_alpha = meanikis_alpha.sort_values(by=['participantID'])\n",
    "subject_scores['meaniki_alpha'] = meanikis_alpha.reset_index()['meanikiAlpha']\n",
    "\n",
    "# Adding SD IKIs for alphabetic characters.\n",
    "sdikis_alpha = all_turbo.groupby('participantID').sdikiAlpha.agg('mean').reset_index()\n",
    "def divby1000(value): # Divides values by 1000 to put on same scale as mean IKIs  \n",
    "    return value/1000 # from in-house typing task.\n",
    "sdikis_alpha['sdikiAlpha'] = sdikis_alpha.sdikiAlpha.transform(divby1000)\n",
    "sdikis_alpha = sdikis_alpha.sort_values(by=['participantID'])\n",
    "subject_scores['sdiki_alpha'] = sdikis_alpha.reset_index()['sdikiAlpha']\n",
    "\n",
    "# Adding CV IKIs for alphabetic characters.\n",
    "cvikis_alpha = all_turbo.groupby('participantID').cvikiAlpha.agg('mean').reset_index()\n",
    "cvikis_alpha = cvikis_alpha.sort_values(by=['participantID'])\n",
    "subject_scores['cviki_alpha'] = cvikis_alpha.reset_index()['cvikiAlpha']\n",
    "\n",
    "# Importing individual global scores calculated from typing task analysis script.\n",
    "globals_dir = save_dir + '/indiv_globalmetrics.csv'\n",
    "indiv_globals = pd.read_csv(globals_dir).drop(['Unnamed: 0'], axis = 1)\n",
    "indiv_globals = indiv_globals[indiv_globals['sID'].isin(ID_list)]\n",
    "indiv_globals = indiv_globals.sort_values(by=['sID']).reset_index(drop=True)\n",
    "\n",
    "subject_scores = pd.concat([subject_scores, indiv_globals], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78fe2f86-9a58-40a8-aace-d6b2dd2dc83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sID</th>\n",
       "      <th>mean_ies</th>\n",
       "      <th>meaniki_alpha</th>\n",
       "      <th>sdiki_alpha</th>\n",
       "      <th>cviki_alpha</th>\n",
       "      <th>sID</th>\n",
       "      <th>mean_IKI</th>\n",
       "      <th>sd_IKI</th>\n",
       "      <th>cv_IKI</th>\n",
       "      <th>mean_RT</th>\n",
       "      <th>sd_RT</th>\n",
       "      <th>cv_RT</th>\n",
       "      <th>mean_deltaiki</th>\n",
       "      <th>total_deltaiki</th>\n",
       "      <th>mean_deltart</th>\n",
       "      <th>total_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s009</td>\n",
       "      <td>258.931703</td>\n",
       "      <td>0.155438</td>\n",
       "      <td>0.109777</td>\n",
       "      <td>0.700639</td>\n",
       "      <td>s009</td>\n",
       "      <td>0.128731</td>\n",
       "      <td>0.066846</td>\n",
       "      <td>0.518988</td>\n",
       "      <td>0.632401</td>\n",
       "      <td>0.065977</td>\n",
       "      <td>0.104103</td>\n",
       "      <td>-0.002352</td>\n",
       "      <td>-0.024184</td>\n",
       "      <td>-0.012846</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s020</td>\n",
       "      <td>473.267482</td>\n",
       "      <td>0.302347</td>\n",
       "      <td>0.250453</td>\n",
       "      <td>0.826906</td>\n",
       "      <td>s020</td>\n",
       "      <td>0.177566</td>\n",
       "      <td>0.106714</td>\n",
       "      <td>0.600633</td>\n",
       "      <td>1.044394</td>\n",
       "      <td>0.236281</td>\n",
       "      <td>0.225705</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.006824</td>\n",
       "      <td>-0.024261</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s176</td>\n",
       "      <td>1682.851715</td>\n",
       "      <td>0.316734</td>\n",
       "      <td>0.241707</td>\n",
       "      <td>0.744973</td>\n",
       "      <td>s176</td>\n",
       "      <td>0.203994</td>\n",
       "      <td>0.085076</td>\n",
       "      <td>0.416814</td>\n",
       "      <td>0.910563</td>\n",
       "      <td>0.169042</td>\n",
       "      <td>0.185223</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>-0.040195</td>\n",
       "      <td>-0.021532</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s207</td>\n",
       "      <td>360.885650</td>\n",
       "      <td>0.208614</td>\n",
       "      <td>0.141034</td>\n",
       "      <td>0.647481</td>\n",
       "      <td>s207</td>\n",
       "      <td>0.164631</td>\n",
       "      <td>0.085433</td>\n",
       "      <td>0.518637</td>\n",
       "      <td>0.869910</td>\n",
       "      <td>0.191214</td>\n",
       "      <td>0.219297</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>-0.006829</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s209</td>\n",
       "      <td>347.896285</td>\n",
       "      <td>0.216724</td>\n",
       "      <td>0.172572</td>\n",
       "      <td>0.786554</td>\n",
       "      <td>s209</td>\n",
       "      <td>0.134536</td>\n",
       "      <td>0.071296</td>\n",
       "      <td>0.529646</td>\n",
       "      <td>0.847502</td>\n",
       "      <td>0.132069</td>\n",
       "      <td>0.155484</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.007503</td>\n",
       "      <td>-0.018694</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s217</td>\n",
       "      <td>230.162116</td>\n",
       "      <td>0.157552</td>\n",
       "      <td>0.080985</td>\n",
       "      <td>0.503416</td>\n",
       "      <td>s217</td>\n",
       "      <td>0.136209</td>\n",
       "      <td>0.049105</td>\n",
       "      <td>0.360322</td>\n",
       "      <td>0.698351</td>\n",
       "      <td>0.123780</td>\n",
       "      <td>0.176868</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>-0.007439</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s240</td>\n",
       "      <td>254.896620</td>\n",
       "      <td>0.151232</td>\n",
       "      <td>0.080480</td>\n",
       "      <td>0.528411</td>\n",
       "      <td>s240</td>\n",
       "      <td>0.153041</td>\n",
       "      <td>0.068443</td>\n",
       "      <td>0.446983</td>\n",
       "      <td>0.604788</td>\n",
       "      <td>0.129137</td>\n",
       "      <td>0.213071</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s254</td>\n",
       "      <td>438.068837</td>\n",
       "      <td>0.301409</td>\n",
       "      <td>0.237287</td>\n",
       "      <td>0.781249</td>\n",
       "      <td>s254</td>\n",
       "      <td>0.264398</td>\n",
       "      <td>0.192641</td>\n",
       "      <td>0.728154</td>\n",
       "      <td>1.096890</td>\n",
       "      <td>0.234291</td>\n",
       "      <td>0.213069</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>-0.018492</td>\n",
       "      <td>-0.004777</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s261</td>\n",
       "      <td>346.531622</td>\n",
       "      <td>0.195963</td>\n",
       "      <td>0.142673</td>\n",
       "      <td>0.715762</td>\n",
       "      <td>s261</td>\n",
       "      <td>0.137397</td>\n",
       "      <td>0.065837</td>\n",
       "      <td>0.478910</td>\n",
       "      <td>0.731690</td>\n",
       "      <td>0.105624</td>\n",
       "      <td>0.144040</td>\n",
       "      <td>-0.002988</td>\n",
       "      <td>-0.031318</td>\n",
       "      <td>-0.010033</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s262</td>\n",
       "      <td>227.275971</td>\n",
       "      <td>0.140412</td>\n",
       "      <td>0.084362</td>\n",
       "      <td>0.583585</td>\n",
       "      <td>s262</td>\n",
       "      <td>0.128899</td>\n",
       "      <td>0.069887</td>\n",
       "      <td>0.541886</td>\n",
       "      <td>0.654782</td>\n",
       "      <td>0.127911</td>\n",
       "      <td>0.194923</td>\n",
       "      <td>-0.001937</td>\n",
       "      <td>-0.007667</td>\n",
       "      <td>-0.019326</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>s263</td>\n",
       "      <td>642.158979</td>\n",
       "      <td>0.303328</td>\n",
       "      <td>0.250644</td>\n",
       "      <td>0.822418</td>\n",
       "      <td>s263</td>\n",
       "      <td>0.183717</td>\n",
       "      <td>0.116893</td>\n",
       "      <td>0.635876</td>\n",
       "      <td>0.961639</td>\n",
       "      <td>0.195911</td>\n",
       "      <td>0.203224</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.036897</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s267</td>\n",
       "      <td>443.028270</td>\n",
       "      <td>0.262948</td>\n",
       "      <td>0.189860</td>\n",
       "      <td>0.714891</td>\n",
       "      <td>s267</td>\n",
       "      <td>0.202628</td>\n",
       "      <td>0.127521</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>1.133152</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.239255</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>-0.035420</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s276</td>\n",
       "      <td>330.493472</td>\n",
       "      <td>0.211428</td>\n",
       "      <td>0.137987</td>\n",
       "      <td>0.629470</td>\n",
       "      <td>s276</td>\n",
       "      <td>0.170663</td>\n",
       "      <td>0.070829</td>\n",
       "      <td>0.414796</td>\n",
       "      <td>0.751736</td>\n",
       "      <td>0.155905</td>\n",
       "      <td>0.206935</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>-0.005367</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>s278</td>\n",
       "      <td>380.654521</td>\n",
       "      <td>0.221195</td>\n",
       "      <td>0.185718</td>\n",
       "      <td>0.828304</td>\n",
       "      <td>s278</td>\n",
       "      <td>0.169984</td>\n",
       "      <td>0.165112</td>\n",
       "      <td>0.970769</td>\n",
       "      <td>0.889133</td>\n",
       "      <td>0.284026</td>\n",
       "      <td>0.318687</td>\n",
       "      <td>-0.004635</td>\n",
       "      <td>-0.042623</td>\n",
       "      <td>-0.017120</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>s279</td>\n",
       "      <td>376.820908</td>\n",
       "      <td>0.304823</td>\n",
       "      <td>0.179833</td>\n",
       "      <td>0.592202</td>\n",
       "      <td>s279</td>\n",
       "      <td>0.239909</td>\n",
       "      <td>0.075076</td>\n",
       "      <td>0.312767</td>\n",
       "      <td>0.951906</td>\n",
       "      <td>0.141134</td>\n",
       "      <td>0.147950</td>\n",
       "      <td>-0.006539</td>\n",
       "      <td>-0.062315</td>\n",
       "      <td>-0.023669</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s282</td>\n",
       "      <td>378.416685</td>\n",
       "      <td>0.284601</td>\n",
       "      <td>0.200638</td>\n",
       "      <td>0.688077</td>\n",
       "      <td>s282</td>\n",
       "      <td>0.244628</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>0.515530</td>\n",
       "      <td>0.915501</td>\n",
       "      <td>0.208885</td>\n",
       "      <td>0.227643</td>\n",
       "      <td>-0.007188</td>\n",
       "      <td>-0.071596</td>\n",
       "      <td>-0.014933</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s283</td>\n",
       "      <td>584.043511</td>\n",
       "      <td>0.204152</td>\n",
       "      <td>0.165734</td>\n",
       "      <td>0.772253</td>\n",
       "      <td>s283</td>\n",
       "      <td>0.157402</td>\n",
       "      <td>0.083042</td>\n",
       "      <td>0.527272</td>\n",
       "      <td>0.773166</td>\n",
       "      <td>0.160453</td>\n",
       "      <td>0.207044</td>\n",
       "      <td>-0.002675</td>\n",
       "      <td>-0.029635</td>\n",
       "      <td>-0.014372</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>s286</td>\n",
       "      <td>353.107552</td>\n",
       "      <td>0.235121</td>\n",
       "      <td>0.133451</td>\n",
       "      <td>0.561427</td>\n",
       "      <td>s286</td>\n",
       "      <td>0.197625</td>\n",
       "      <td>0.095206</td>\n",
       "      <td>0.481479</td>\n",
       "      <td>0.902645</td>\n",
       "      <td>0.232038</td>\n",
       "      <td>0.256480</td>\n",
       "      <td>-0.001529</td>\n",
       "      <td>-0.018843</td>\n",
       "      <td>-0.007383</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s302</td>\n",
       "      <td>289.125596</td>\n",
       "      <td>0.188403</td>\n",
       "      <td>0.134785</td>\n",
       "      <td>0.694457</td>\n",
       "      <td>s302</td>\n",
       "      <td>0.162639</td>\n",
       "      <td>0.100860</td>\n",
       "      <td>0.619808</td>\n",
       "      <td>0.704336</td>\n",
       "      <td>0.155765</td>\n",
       "      <td>0.220672</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.018031</td>\n",
       "      <td>-0.020626</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>s304</td>\n",
       "      <td>304.790181</td>\n",
       "      <td>0.156890</td>\n",
       "      <td>0.090636</td>\n",
       "      <td>0.565021</td>\n",
       "      <td>s304</td>\n",
       "      <td>0.133587</td>\n",
       "      <td>0.055218</td>\n",
       "      <td>0.413115</td>\n",
       "      <td>0.654566</td>\n",
       "      <td>0.121982</td>\n",
       "      <td>0.185932</td>\n",
       "      <td>-0.002037</td>\n",
       "      <td>-0.012120</td>\n",
       "      <td>-0.021263</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>s305</td>\n",
       "      <td>240.596369</td>\n",
       "      <td>0.157725</td>\n",
       "      <td>0.112215</td>\n",
       "      <td>0.684591</td>\n",
       "      <td>s305</td>\n",
       "      <td>0.130578</td>\n",
       "      <td>0.053307</td>\n",
       "      <td>0.408024</td>\n",
       "      <td>0.635926</td>\n",
       "      <td>0.134097</td>\n",
       "      <td>0.210418</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>-0.032982</td>\n",
       "      <td>-0.023938</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>s306</td>\n",
       "      <td>328.628323</td>\n",
       "      <td>0.183354</td>\n",
       "      <td>0.116768</td>\n",
       "      <td>0.603060</td>\n",
       "      <td>s306</td>\n",
       "      <td>0.164475</td>\n",
       "      <td>0.071223</td>\n",
       "      <td>0.432794</td>\n",
       "      <td>0.667531</td>\n",
       "      <td>0.124380</td>\n",
       "      <td>0.185914</td>\n",
       "      <td>-0.003404</td>\n",
       "      <td>-0.030595</td>\n",
       "      <td>-0.015971</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>s309</td>\n",
       "      <td>456.562602</td>\n",
       "      <td>0.299488</td>\n",
       "      <td>0.225987</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>s309</td>\n",
       "      <td>0.207874</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.726951</td>\n",
       "      <td>0.845183</td>\n",
       "      <td>0.152196</td>\n",
       "      <td>0.179655</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>-0.058666</td>\n",
       "      <td>-0.023143</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>s311</td>\n",
       "      <td>272.908201</td>\n",
       "      <td>0.168441</td>\n",
       "      <td>0.116212</td>\n",
       "      <td>0.688631</td>\n",
       "      <td>s311</td>\n",
       "      <td>0.099825</td>\n",
       "      <td>0.053828</td>\n",
       "      <td>0.538919</td>\n",
       "      <td>0.661567</td>\n",
       "      <td>0.123061</td>\n",
       "      <td>0.185589</td>\n",
       "      <td>-0.003213</td>\n",
       "      <td>-0.023589</td>\n",
       "      <td>-0.009406</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sID     mean_ies  meaniki_alpha  sdiki_alpha  cviki_alpha   sID  \\\n",
       "0   s009   258.931703       0.155438     0.109777     0.700639  s009   \n",
       "1   s020   473.267482       0.302347     0.250453     0.826906  s020   \n",
       "2   s176  1682.851715       0.316734     0.241707     0.744973  s176   \n",
       "3   s207   360.885650       0.208614     0.141034     0.647481  s207   \n",
       "4   s209   347.896285       0.216724     0.172572     0.786554  s209   \n",
       "5   s217   230.162116       0.157552     0.080985     0.503416  s217   \n",
       "6   s240   254.896620       0.151232     0.080480     0.528411  s240   \n",
       "7   s254   438.068837       0.301409     0.237287     0.781249  s254   \n",
       "8   s261   346.531622       0.195963     0.142673     0.715762  s261   \n",
       "9   s262   227.275971       0.140412     0.084362     0.583585  s262   \n",
       "10  s263   642.158979       0.303328     0.250644     0.822418  s263   \n",
       "11  s267   443.028270       0.262948     0.189860     0.714891  s267   \n",
       "12  s276   330.493472       0.211428     0.137987     0.629470  s276   \n",
       "13  s278   380.654521       0.221195     0.185718     0.828304  s278   \n",
       "14  s279   376.820908       0.304823     0.179833     0.592202  s279   \n",
       "15  s282   378.416685       0.284601     0.200638     0.688077  s282   \n",
       "16  s283   584.043511       0.204152     0.165734     0.772253  s283   \n",
       "17  s286   353.107552       0.235121     0.133451     0.561427  s286   \n",
       "18  s302   289.125596       0.188403     0.134785     0.694457  s302   \n",
       "19  s304   304.790181       0.156890     0.090636     0.565021  s304   \n",
       "20  s305   240.596369       0.157725     0.112215     0.684591  s305   \n",
       "21  s306   328.628323       0.183354     0.116768     0.603060  s306   \n",
       "22  s309   456.562602       0.299488     0.225987     0.740586  s309   \n",
       "23  s311   272.908201       0.168441     0.116212     0.688631  s311   \n",
       "\n",
       "    mean_IKI    sd_IKI    cv_IKI   mean_RT     sd_RT     cv_RT  mean_deltaiki  \\\n",
       "0   0.128731  0.066846  0.518988  0.632401  0.065977  0.104103      -0.002352   \n",
       "1   0.177566  0.106714  0.600633  1.044394  0.236281  0.225705       0.000885   \n",
       "2   0.203994  0.085076  0.416814  0.910563  0.169042  0.185223      -0.004743   \n",
       "3   0.164631  0.085433  0.518637  0.869910  0.191214  0.219297      -0.000987   \n",
       "4   0.134536  0.071296  0.529646  0.847502  0.132069  0.155484      -0.000357   \n",
       "5   0.136209  0.049105  0.360322  0.698351  0.123780  0.176868       0.000219   \n",
       "6   0.153041  0.068443  0.446983  0.604788  0.129137  0.213071      -0.000728   \n",
       "7   0.264398  0.192641  0.728154  1.096890  0.234291  0.213069       0.001963   \n",
       "8   0.137397  0.065837  0.478910  0.731690  0.105624  0.144040      -0.002988   \n",
       "9   0.128899  0.069887  0.541886  0.654782  0.127911  0.194923      -0.001937   \n",
       "10  0.183717  0.116893  0.635876  0.961639  0.195911  0.203224      -0.002954   \n",
       "11  0.202628  0.127521  0.628975  1.133152  0.271739  0.239255      -0.000220   \n",
       "12  0.170663  0.070829  0.414796  0.751736  0.155905  0.206935       0.001883   \n",
       "13  0.169984  0.165112  0.970769  0.889133  0.284026  0.318687      -0.004635   \n",
       "14  0.239909  0.075076  0.312767  0.951906  0.141134  0.147950      -0.006539   \n",
       "15  0.244628  0.126185  0.515530  0.915501  0.208885  0.227643      -0.007188   \n",
       "16  0.157402  0.083042  0.527272  0.773166  0.160453  0.207044      -0.002675   \n",
       "17  0.197625  0.095206  0.481479  0.902645  0.232038  0.256480      -0.001529   \n",
       "18  0.162639  0.100860  0.619808  0.704336  0.155765  0.220672      -0.001813   \n",
       "19  0.133587  0.055218  0.413115  0.654566  0.121982  0.185932      -0.002037   \n",
       "20  0.130578  0.053307  0.408024  0.635926  0.134097  0.210418      -0.004092   \n",
       "21  0.164475  0.071223  0.432794  0.667531  0.124380  0.185914      -0.003404   \n",
       "22  0.207874  0.151202  0.726951  0.845183  0.152196  0.179655      -0.005039   \n",
       "23  0.099825  0.053828  0.538919  0.661567  0.123061  0.185589      -0.003213   \n",
       "\n",
       "    total_deltaiki  mean_deltart  total_error  \n",
       "0        -0.024184     -0.012846         18.0  \n",
       "1         0.006824     -0.024261         45.0  \n",
       "2        -0.040195     -0.021532         50.0  \n",
       "3        -0.006829      0.000042         55.0  \n",
       "4        -0.007503     -0.018694         43.0  \n",
       "5         0.004319     -0.007439         18.0  \n",
       "6        -0.007394     -0.004336         10.0  \n",
       "7        -0.018492     -0.004777         91.0  \n",
       "8        -0.031318     -0.010033         32.0  \n",
       "9        -0.007667     -0.019326         23.0  \n",
       "10       -0.036897      0.003304         78.0  \n",
       "11       -0.003247     -0.035420         34.0  \n",
       "12        0.016439     -0.005367         34.0  \n",
       "13       -0.042623     -0.017120         61.0  \n",
       "14       -0.062315     -0.023669          7.0  \n",
       "15       -0.071596     -0.014933         51.0  \n",
       "16       -0.029635     -0.014372         67.0  \n",
       "17       -0.018843     -0.007383         52.0  \n",
       "18       -0.018031     -0.020626         14.0  \n",
       "19       -0.012120     -0.021263         42.0  \n",
       "20       -0.032982     -0.023938         13.0  \n",
       "21       -0.030595     -0.015971         19.0  \n",
       "22       -0.058666     -0.023143         65.0  \n",
       "23       -0.023589     -0.009406         67.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ADDRESS/EDIT THIS LATER ###\n",
    "\n",
    "# Dropping data from new subjects that won't be included in first paper.\n",
    "subject_scores = subject_scores.dropna()\n",
    "subject_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "712f0bab-dced-4032-ad34-e6e848be0a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.33564142727247237, pvalue=0.10883869954088668)\n",
      "PearsonRResult(statistic=0.16235239853101952, pvalue=0.44847986892395253)\n",
      "PearsonRResult(statistic=-0.016666184002187785, pvalue=0.9383898708634373)\n",
      "PearsonRResult(statistic=0.3649907711058864, pvalue=0.07948042995426248)\n",
      "PearsonRResult(statistic=0.19904111212656178, pvalue=0.3511192808934843)\n",
      "PearsonRResult(statistic=0.008313540163602202, pvalue=0.9692458389120489)\n",
      "PearsonRResult(statistic=-0.2219377649297897, pvalue=0.2972741383300595)\n",
      "PearsonRResult(statistic=-0.24467171376619748, pvalue=0.24920883239328573)\n",
      "PearsonRResult(statistic=-0.12192561729162074, pvalue=0.5703413399016535)\n",
      "PearsonRResult(statistic=0.3160624723863282, pvalue=0.13242648362994738)\n"
     ]
    }
   ],
   "source": [
    "# Pearson correlations between mean IES and typing task metrics.\n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['mean_IKI']))\n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['sd_IKI']))\n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['cv_IKI']))\n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['mean_RT']))\n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['sd_RT']))\n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['cv_RT'])) \n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['mean_deltaiki']))\n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['total_deltaiki']))\n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['mean_deltart']))\n",
    "print(pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['total_error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec564fa1-579b-4725-bc5e-150fb8e4d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IKI: PearsonRResult(statistic=0.8346352275594588, pvalue=3.9686240840398434e-07)\n",
      "SD IKI: PearsonRResult(statistic=0.7115157517971853, pvalue=9.680494713354588e-05)\n",
      "CV IKI: PearsonRResult(statistic=0.6733589598700805, pvalue=0.00031050653486556156)\n",
      "Bonferonni p-vals [1.190587225211953e-06, 0.00029041484140063765, 0.0009315196045966847]\n",
      "FDR p-vals [1.19058723e-06 1.45207421e-04 3.10506535e-04]\n"
     ]
    }
   ],
   "source": [
    "# Pearson correlation between mean, SD, and CV IKI from Turbo and Typing tasks.\n",
    "print('Mean IKI:', pearsonr(subject_scores['meaniki_alpha'],\n",
    "               subject_scores['mean_IKI']))\n",
    "print('SD IKI:', pearsonr(subject_scores['sdiki_alpha'],\n",
    "               subject_scores['sd_IKI']))\n",
    "print('CV IKI:', pearsonr(subject_scores['cviki_alpha'],\n",
    "               subject_scores['cv_IKI']))\n",
    "\n",
    "# Making list of Pearson results. \n",
    "alpha_pearsons = [\n",
    "    (pearsonr(subject_scores['meaniki_alpha'], \n",
    "              subject_scores['mean_IKI'])),\n",
    "    (pearsonr(subject_scores['sdiki_alpha'],\n",
    "              subject_scores['sd_IKI'])),\n",
    "    (pearsonr(subject_scores['cviki_alpha'],\n",
    "              subject_scores['cv_IKI']))]\n",
    "\n",
    "# List of only p-values\n",
    "alpha_pvals = [val[1] for val in alpha_pearsons]\n",
    "\n",
    "# Running Bonferonni correction\n",
    "bon_alphaps = [p*len(alpha_pvals) for p in alpha_pvals]\n",
    "print('Bonferonni p-vals', bon_alphaps)\n",
    "\n",
    "# Running False Discovery Rate test\n",
    "print('FDR p-vals', stats.false_discovery_control(alpha_pvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f69c67e-7d60-4b7e-abe0-12c0975d334f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48977415, 0.6727198 , 0.96924584, 0.48977415, 0.63201471,\n",
       "       0.96924584, 0.63201471, 0.63201471, 0.73329601])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pearson correlation between ... \n",
    "ies_pearsons = [\n",
    "    (pearsonr(subject_scores['mean_ies'],\n",
    "             subject_scores['mean_IKI'])),\n",
    "    (pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['sd_IKI'])),\n",
    "    (pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['cv_IKI'])),\n",
    "    (pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['mean_RT'])),\n",
    "    (pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['sd_RT'])),\n",
    "    (pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['cv_RT'])),\n",
    "    (pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['mean_deltaiki'])),\n",
    "    (pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['total_deltaiki'])),\n",
    "    (pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['mean_deltart']))\n",
    "] \n",
    "\n",
    "# List of only p-values\n",
    "pvals = [val[1] for val in ies_pearsons]\n",
    "\n",
    "# Running Bonferonni correction\n",
    "bon_ps = [p*len(pvals) for p in pvals]\n",
    "\n",
    "# Running False Discovery Rate test\n",
    "stats.false_discovery_control(pvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f477cc09-2856-4187-b81a-d3429c1cab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pearsonr(subject_scores['mean_ies'],\n",
    "               subject_scores['mean_deltart'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
